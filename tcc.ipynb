{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importação",
   "id": "2cd30e7f58b7f010"
  },
  {
   "metadata": {
    "tags": [
     "init",
     "startup"
    ]
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import json\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import pickle\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch, het_breuschpagan, het_white\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.tsa.stattools as ts\n",
    "from scipy.stats import ttest_1samp, gaussian_kde, ttest_ind, percentileofscore, jarque_bera\n",
    "import scipy.stats as stats\n",
    "import locale\n",
    "import math\n",
    "import struct\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')"
   ],
   "id": "c1f962e0b2dfaa42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if \"conn\" not in globals() or conn is None:\n",
    "    conn = sqlite3.connect(\"data/bancoDados.db\")\n",
    "    print(\"Conexão com o banco de dados criada!\")\n",
    "\n",
    "try:\n",
    "    # Teste simples para verificar se a conexão está ativa\n",
    "    conn.execute(\"SELECT 1\")\n",
    "except sqlite3.ProgrammingError as e:\n",
    "    print(\"A conexão com o banco de dados foi fechada, recriando...\")\n",
    "    conn = sqlite3.connect(\"data/bancoDados.db\")"
   ],
   "id": "75fbd188e37b9264",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Modelos de dados:\n",
    "\n",
    "Utilizado para unificar os tickers das bolsas diferentes"
   ],
   "id": "7a0823acec4c9439"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class TickerData:\n",
    "    ticker_name: str\n",
    "    sector: str = \"\"\n",
    "    sector_key: str = \"\"\n",
    "    industry: str = \"\"\n",
    "    industry_key: str = \"\"\n",
    "    dividend_rate: float = np.nan\n",
    "    dividend_yield: float = np.nan\n",
    "    full_exchange_name: str = \"\"\n",
    "    ex_dividend_date: str = \"\"\n",
    "    payout_ratio: float = np.nan\n",
    "    beta: float = np.nan\n",
    "    market_cap: float = np.nan\n",
    "    price_to_earnings: float = np.nan\n",
    "    price_to_book: float = np.nan\n",
    "    return_on_equity: float = np.nan\n",
    "    free_cashflow: float = np.nan\n",
    "    incorporation_year: int = None\n",
    "\n",
    "    yahoo_ticker: yf.Ticker = None\n",
    "    yahoo_ticker_information: dict = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "\n",
    "        if hasattr(self, \"_skip_init\") and self._skip_init:\n",
    "            return  # Pula a inicialização automática\n",
    "\n",
    "        self.yahoo_ticker = yf.Ticker(self.ticker_name)\n",
    "        self.yahoo_ticker_information = self.yahoo_ticker.info\n",
    "\n",
    "        self.sector = self.yahoo_ticker_information.get(\"sector\", \"N/A\")\n",
    "        self.sector_key = self.yahoo_ticker_information.get(\"sectorKey\", \"N/A\")\n",
    "        self.industry = self.yahoo_ticker_information.get(\"industry\", \"N/A\")\n",
    "        self.industry_key = self.yahoo_ticker_information.get(\"industryKey\", \"N/A\")\n",
    "\n",
    "        self.dividend_rate = self.yahoo_ticker_information.get(\"dividendRate\", np.nan)\n",
    "        self.dividend_yield = self.yahoo_ticker_information.get(\"dividendYield\", np.nan)\n",
    "        self.full_exchange_name = self.yahoo_ticker_information.get(\"fullExchangeName\", \"N/A\")\n",
    "        self.ex_dividend_date = self.yahoo_ticker_information.get(\"exDividendDate\", \"N/A\")\n",
    "        self.payout_ratio = self.yahoo_ticker_information.get(\"payoutRatio\", np.nan)\n",
    "\n",
    "        self.beta = self.yahoo_ticker_information.get(\"beta\", np.nan)\n",
    "        self.market_cap = self.yahoo_ticker_information.get(\"marketCap\", np.nan)\n",
    "        self.price_to_earnings = self.yahoo_ticker_information.get(\"trailingPE\", np.nan)\n",
    "        self.price_to_book = self.yahoo_ticker_information.get(\"priceToBook\", np.nan)\n",
    "        self.return_on_equity = self.yahoo_ticker_information.get(\"returnOnEquity\", np.nan)\n",
    "        self.free_cashflow = self.yahoo_ticker_information.get(\"freeCashflow\", np.nan)\n",
    "\n",
    "    @classmethod\n",
    "    def create_without_init(cls, source):\n",
    "        \"\"\"\n",
    "        Cria um objeto TickerData sem rodar o __post_init__.\n",
    "        O parâmetro `source` pode ser:\n",
    "        - Um `ticker_name` (str)\n",
    "        - Um objeto `TickerData`\n",
    "        - Um dicionário com os mesmos atributos\n",
    "        \"\"\"\n",
    "        if isinstance(source, str):  # Criar com um ticker_name\n",
    "            obj = cls(source)\n",
    "\n",
    "        elif isinstance(source, TickerData):  # Copiar de outro objeto TickerData\n",
    "            obj = cls(**source.__dict__)\n",
    "\n",
    "        elif isinstance(source, dict):  # Criar a partir de um dicionário\n",
    "            obj = cls(**source)\n",
    "            obj.yahoo_ticker = yf.Ticker(obj.ticker_name)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Fonte inválida! Passe um ticker_name (str), um objeto TickerData ou um dicionário.\")\n",
    "\n",
    "        obj._skip_init = True  # Evita que o __post_init__ rode automaticamente\n",
    "        return obj"
   ],
   "id": "82b2dfbe99a9e33c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24e439525314b4a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Funções importantes:"
   ]
  },
  {
   "cell_type": "code",
   "id": "e9f01cd505a4223",
   "metadata": {},
   "source": [
    "def salvar_dict(dicionario, arquivo=\"dados.pkl\"):\n",
    "    \"\"\"Salva um dicionário em um arquivo pickle.\"\"\"\n",
    "    with open(arquivo, \"wb\") as f:\n",
    "        pickle.dump(dicionario, f)\n",
    "    print(f\"✅ Dicionário salvo em {arquivo}\")\n",
    "\n",
    "def carregar_dict(arquivo=\"dados.pkl\"):\n",
    "    \"\"\"Carrega um dicionário de um arquivo pickle.\"\"\"\n",
    "    try:\n",
    "        with open(arquivo, \"rb\") as f:\n",
    "            dicionario = pickle.load(f)\n",
    "        print(\"✅ Dicionário carregado com sucesso!\")\n",
    "        return dicionario\n",
    "    except FileNotFoundError:\n",
    "        print(\"⚠️ Arquivo não encontrado. Retornando um dicionário vazio.\")\n",
    "        return {}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def formatar_numero(numero, decimal_places=0):\n",
    "    formato = f\"%.{decimal_places}f\" if decimal_places > 0 else \"%d\"\n",
    "    return locale.format_string(formato, numero, grouping=True)"
   ],
   "id": "26923ca67ae91d12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class StdevFunc:\n",
    "    def __init__(self):\n",
    "        self.M = 0.0\n",
    "        self.S = 0.0\n",
    "        self.k = 1\n",
    "\n",
    "    def step(self, value):\n",
    "        if value is None:\n",
    "            return\n",
    "        tM = self.M\n",
    "        self.M += (value - tM) / self.k\n",
    "        self.S += (value - tM) * (value - self.M)\n",
    "        self.k += 1\n",
    "\n",
    "    def finalize(self):\n",
    "        if self.k < 3:\n",
    "            return None\n",
    "        return math.sqrt(self.S / (self.k-2))"
   ],
   "id": "b0a478915d0ffee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Padronização dos Graficos",
   "id": "6ddb3217d3deb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_density(\n",
    "    data: pd.Series,\n",
    "    title: str = \"Gráfico de Distribuição\",\n",
    "    xlabel: str = \"Valor\",\n",
    "    ylabel: str = \"Densidade\",\n",
    "    figsize: tuple[int, int] = (10, 6)\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Gera um gráfico de densidade para uma Série Pandas.\n",
    "\n",
    "    Parâmetros:\n",
    "    - data (pd.Series): Série Pandas contendo os dados numéricos a serem analisados.\n",
    "    - title (str, opcional): Título do gráfico (padrão: \"Gráfico de Distribuição\").\n",
    "    - xlabel (str, opcional): Rótulo do eixo X (padrão: \"Valor\").\n",
    "    - ylabel (str, opcional): Rótulo do eixo Y (padrão: \"Densidade\").\n",
    "    - figsize (tuple[int, int], opcional): Tamanho da figura em polegadas (padrão: (10, 6)).\n",
    "\n",
    "    Retorno:\n",
    "    - None: Exibe o gráfico diretamente.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcular estatísticas\n",
    "    media = data.mean()\n",
    "    desvio_padrao = data.std()\n",
    "\n",
    "    # Criar a figura e definir a cor de fundo branca\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Criar o gráfico de densidade\n",
    "    sns.kdeplot(data, fill=True, label=\"Densidade\", linewidth=1.5, ax=ax)\n",
    "\n",
    "    # Adicionar linhas da média e dos desvios padrão\n",
    "    ax.axvline(media, color='r', linestyle='dashed', linewidth=1, label=f'Média: {media:.4f}')\n",
    "    ax.axvline(media, color='black', linestyle='none', linewidth=0, label=f'σ: {desvio_padrao:.4f}')\n",
    "    ax.axvline(media + desvio_padrao, color='g', linestyle='dashed', linewidth=1, label='- + 1σ')\n",
    "    ax.axvline(media - desvio_padrao, color='g', linestyle='dashed', linewidth=1)\n",
    "    ax.axvline(media + 2 * desvio_padrao, color='b', linestyle='dashed', linewidth=1, label='- + 2σ')\n",
    "    ax.axvline(media - 2 * desvio_padrao, color='b', linestyle='dashed', linewidth=1)\n",
    "    ax.axvline(media + 3 * desvio_padrao, color='purple', linestyle='dashed', linewidth=1, label='- + 3σ')\n",
    "    ax.axvline(media - 3 * desvio_padrao, color='purple', linestyle='dashed', linewidth=1)\n",
    "\n",
    "    # Criar contorno preto nos eixos X e Y (efeito \"L\")\n",
    "    ax.axhline(0, color='black', linewidth=1.5)  # Contorno do eixo X\n",
    "    ax.axvline(media - 4 * desvio_padrao, color='black', linewidth=1.5)  # Contorno do eixo Y\n",
    "\n",
    "    # Definir os limites do eixo X\n",
    "    ax.set_xlim(media - 4 * desvio_padrao, media + 4 * desvio_padrao)\n",
    "\n",
    "    # Configurar rótulos e título\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "    # Exibir o gráfico\n",
    "    return plt"
   ],
   "id": "c8f315c9750ba0b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ca7bb6f58bdb166",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Obtendo os ativos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc728515c3f2692",
   "metadata": {},
   "source": [
    "## NYSE\n",
    "\n",
    "Feito atraves de um \"WebScrapping\" da pagina da Nyse"
   ]
  },
  {
   "cell_type": "code",
   "id": "3380a2f6a8cedb3d",
   "metadata": {},
   "source": [
    "async def fetch_page_NYSE(session, page):\n",
    "    url = \"https://www.nyse.com/api/quotes/filter\"\n",
    "    payload = {\n",
    "        \"instrumentType\": \"EQUITY\",\n",
    "        \"pageNumber\": page,\n",
    "        \"sortColumn\": \"NORMALIZED_TICKER\",\n",
    "        \"sortOrder\": \"ASC\",\n",
    "        \"maxResultsPerPage\": 10,\n",
    "        \"filterToken\": \"\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9,pt-BR;q=0.8,pt;q=0.7\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Origin\": \"https://www.nyse.com\",\n",
    "        \"Referer\": \"https://www.nyse.com/listings_directory/stock\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    async with session.post(url, json=payload, headers=headers) as response:\n",
    "        data = await response.json()\n",
    "        return data\n",
    "\n",
    "async def fetch_all_assets_NYSE():\n",
    "    assets = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Primeiro, colete a primeira página para determinar o total de ativos.\n",
    "        print(\"Coletando a primeira página para obter o total de ativos...\")\n",
    "        first_page = await fetch_page_NYSE(session, 1)\n",
    "        if not first_page:\n",
    "            print(\"Falha ao coletar a primeira página.\")\n",
    "            return assets\n",
    "\n",
    "        # Supondo que o campo \"total\" esteja presente no primeiro item:\n",
    "        total_assets = first_page[0].get(\"total\", 0) if first_page and len(first_page) > 0 else 0\n",
    "        pages = (total_assets // 10) + (1 if total_assets % 10 != 0 else 0)\n",
    "        print(f\"Total de ativos: {total_assets}. Páginas a coletar: {pages}\")\n",
    "        assets.extend(first_page)\n",
    "\n",
    "        # Loop pelas páginas restantes\n",
    "        for page in range(2, pages + 1):\n",
    "            print(f\"Coletando página {page}...\")\n",
    "            page_data = await fetch_page_NYSE(session, page)\n",
    "            assets.extend(page_data)\n",
    "            print(f\"Página {page} coletada com {len(page_data)} ativos.\")\n",
    "            # Aguarde 1 segundo entre as requisições para evitar bloqueios\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "    return assets\n",
    "\n",
    "all_assets = await fetch_all_assets_NYSE()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92fedbe5614b84ae",
   "metadata": {},
   "source": [
    "pd.DataFrame(all_assets).to_csv(\"data/NYSE_PAPERS.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8b39a8a450de63ba",
   "metadata": {},
   "source": [
    "## NASDAQ\n",
    "\n",
    "Obtido aqui: https://www.nasdaq.com/market-activity/stocks/screener?page=118&rows_per_page=25"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d9f910aded3b344",
   "metadata": {},
   "source": [
    "pd.read_csv(\"data/NASDAQ_PAPERS.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Alimentação da tabela \"tickers\"\n",
   "id": "74d96d5736ed9e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "obter_ativos_utilizados = \"\"\"\n",
    "SELECT * FROM tickers_ativos\n",
    "\"\"\"\n",
    "\n",
    "df_tickers_ativos = pd.read_sql(obter_ativos_utilizados, conn)"
   ],
   "id": "f034d74ef55dea4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "todos_tickers: list[TickerData] = []\n",
    "for  in tqdm(df_tickers_ativos[\"ticker_name\"]):\n",
    "    todos_tickers.append(TickerData())"
   ],
   "id": "a7b5f6a7794406ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for ticker_row in tqdm(todos_tickers):\n",
    "    ticker_row.yahoo_ticker = None\n",
    "    ticker_row.yahoo_ticker_information = str(ticker_row.yahoo_ticker_information)"
   ],
   "id": "a16bf521c9f93ca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_todos_tickers = pd.DataFrame(todos_tickers)",
   "id": "dd9ff7f452f725c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_todos_tickers.drop([\"yahoo_ticker\"], axis=1, inplace=True)",
   "id": "1c41201aeeb65d8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_todos_tickers.to_sql(\"tickers\",conn, if_exists=\"replace\",index=False)",
   "id": "e4d72d8d2b7257c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tickers de Mercado",
   "id": "911d1cce86f82cc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tickers = ['^NYA', '^IXIC']\n",
    "\n",
    "tickers_mercado = [TickerData(ticker) for ticker in tickers]"
   ],
   "id": "20966309b1d9b78a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for ticker_row in tqdm(tickers_mercado):\n",
    "    ticker_row.yahoo_ticker = None\n",
    "    ticker_row.yahoo_ticker_information = str(ticker_row.yahoo_ticker_information)"
   ],
   "id": "6f765385d6f1563c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ativos_mercado = pd.DataFrame(tickers_mercado)",
   "id": "b201a784e546b2c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ativos_mercado.to_sql(\"tickers_mercado\",conn, if_exists=\"replace\",index=False)",
   "id": "ed5bd546345dd324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_date = \"2014-01-01\"\n",
    "tickers_descartados_cotacao = []\n",
    "tickers_descartados_dividendo = []\n",
    "tickers_descartados_erro = []\n",
    "\n",
    "for ticker_row in tqdm(tickers, desc=\"Processando Tickers\"):\n",
    "    stock = yf.Ticker(ticker_row)\n",
    "    # Cotações: Verifica se há dados e se cobrem mais de 10 anos\n",
    "    try:\n",
    "        prices = stock.history(\n",
    "                        start=start_date,\n",
    "                        interval=\"1d\",\n",
    "                        auto_adjust=False,\n",
    "                        back_adjust=False,\n",
    "                        raise_errors=True\n",
    "        ).reset_index()\n",
    "\n",
    "        if not prices.empty:\n",
    "            # Calcula os anos entre a primeira e a última data\n",
    "            start_year = prices['Date'].iloc[0].year\n",
    "            end_year = prices['Date'].iloc[-1].year\n",
    "            years_of_data = end_year - start_year\n",
    "\n",
    "            # Verifica se há menos de 10 anos de dados\n",
    "            if years_of_data < 10:\n",
    "                tickers_descartados_cotacao.append(ticker_row)\n",
    "                continue\n",
    "\n",
    "            # Se dados válidos, prossegue com o processamento\n",
    "            prices['ticker_name'] = ticker_row\n",
    "            prices.to_sql(\"prices\", conn, if_exists=\"append\", index=False)\n",
    "        else:\n",
    "            tickers_descartados_cotacao.append(ticker_row)\n",
    "            continue\n",
    "\n",
    "    except Exception as e:\n",
    "        tickers_descartados_erro.append(ticker_row)\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    time.sleep(0.3)  # Pausa para evitar sobrecarga na API"
   ],
   "id": "a96b28d96d528a0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fe08586d40e35402",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Formalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "id": "e5c945ff6dceb5b0",
   "metadata": {},
   "source": [
    "todos_tickers: list[TickerData] = []\n",
    "tickers_descartados: list[str] = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ae746e06158cdcbe",
   "metadata": {},
   "source": [
    "## NYSE"
   ]
  },
  {
   "cell_type": "code",
   "id": "54ebe4940532e6ce",
   "metadata": {},
   "source": [
    "origem = pd.read_csv(\"data/NYSE_PAPERS.csv\")\n",
    "total_tickers = len(origem['symbolTicker'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4eb635bfafde3842",
   "metadata": {},
   "source": [
    "realizado = 0\n",
    "for ticker_row in origem['symbolTicker']:\n",
    "    print(f\"Progresso: {realizado/total_tickers*100:.2f}%\")\n",
    "    try:\n",
    "        todos_tickers.append(TickerData(ticker_row))\n",
    "    except Exception as e:\n",
    "        tickers_descartados.append(ticker_row)\n",
    "        print(f\"Ticker {ticker_row} descartado por motivos de: {str(e)}\")\n",
    "    time.sleep(.5)\n",
    "    realizado +=1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d983f51fda8fca50",
   "metadata": {},
   "source": [
    "copia_todos_tickers = todos_tickers.copy()\n",
    "\n",
    "for copia_ticker in copia_todos_tickers:\n",
    "    copia_ticker.yahoo_ticker = \"\"\n",
    "\n",
    "dados_tickers = {\n",
    "    \"todos_tickers\": todos_tickers,\n",
    "    \"tickers_descartados\": tickers_descartados\n",
    "}\n",
    "\n",
    "salvar_dict(dados_tickers, \"data/dados_tickers_NYSE.pkl\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "409fe8759d22a17",
   "metadata": {},
   "source": [
    "teste = todos_tickers[0]\n",
    "teste.yahoo_ticker = \"\"\n",
    "salvar_dict({\"teste\":teste}, \"data/dados_tickers_NYSE.pkl\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Verificação Posterior",
   "id": "e2998a43d6e55ca9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "todos_tickers: pd.DataFrame = origem['symbolTicker']",
   "id": "1f52581ca95a8a4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "original = len(todos_tickers)",
   "id": "7d6d02e78a78cd68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tickers_nyse_list = todos_tickers.to_list()",
   "id": "1d5b141690c1e54a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "placeholders = ', '.join(['(?, \"NYSE\")'] * len(tickers_nyse_list))  # Gera um (?,?,?) dinâmico\n",
    "query = f\"INSERT INTO tickers_brutos (ticker_name, origem) VALUES {placeholders}\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query, tickers_nyse_list)\n",
    "\n",
    "conn.commit()"
   ],
   "id": "460cf61fc70e89d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "895492ec517d6460",
   "metadata": {},
   "source": [
    "## NASDAQ"
   ]
  },
  {
   "cell_type": "code",
   "id": "53bf2c87b491c768",
   "metadata": {},
   "source": [
    "nasdaq_dados = pd.read_csv(\"data/NASDAQ_PAPERS.csv\")\n",
    "total_tickers_nasdaq = len(nasdaq_dados['Symbol'])\n",
    "todos_tickers_nasdaq = []\n",
    "tickers_descartados_nasdaq = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c5f4a1447bc370f",
   "metadata": {},
   "source": [
    "total_tickers_nasdaq"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a11061d240fa6607",
   "metadata": {},
   "source": [
    "realizado = 0\n",
    "for ticker_row in nasdaq_dados['Symbol']:\n",
    "    print(f\"Progresso: {realizado/total_tickers_nasdaq*100:.2f}%\")\n",
    "    try:\n",
    "        todos_tickers_nasdaq.append(TickerData(ticker_row))\n",
    "    except Exception as e:\n",
    "        tickers_descartados_nasdaq.append(ticker_row)\n",
    "        print(f\"Ticker {ticker_row} descartado por motivos de: {str(e)}\")\n",
    "    time.sleep(.5)\n",
    "    realizado +=1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df0805824ebfeeea",
   "metadata": {},
   "source": [
    "copia_todos_tickers = todos_tickers_nasdaq.copy()\n",
    "\n",
    "for copia_ticker in copia_todos_tickers:\n",
    "    copia_ticker.yahoo_ticker = \"\"\n",
    "\n",
    "dados_tickers_nasdaq = {\n",
    "    \"todos_tickers\": todos_tickers_nasdaq,\n",
    "    \"tickers_descartados\": tickers_descartados_nasdaq\n",
    "}\n",
    "\n",
    "salvar_dict(dados_tickers_nasdaq, \"data/dados_tickers_NASDAQ.pkl\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Verificação Posterior:",
   "id": "9505eed1f680f0ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dados_nasdaq_lista = nasdaq_dados['Symbol'].to_list()",
   "id": "641135c9f95de7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(dados_nasdaq_lista)",
   "id": "b9896e0a4ce350dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "placeholders = ', '.join(['(?, \"NASDAQ\")'] * len(dados_nasdaq_lista))  # Gera um (?,?,?) dinâmico\n",
    "query = f\"INSERT INTO tickers_brutos (ticker_name, origem) VALUES {placeholders}\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query, dados_nasdaq_lista)\n",
    "\n",
    "conn.commit()"
   ],
   "id": "594229a7e9553d6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4ab09db94238337",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Banco de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619885e8382b8355",
   "metadata": {},
   "source": [
    "## Dados para trabalho"
   ]
  },
  {
   "cell_type": "code",
   "id": "fa164486dcc42a32",
   "metadata": {},
   "source": [
    "dados_completos = [*todos_tickers_nasdaq, *todos_tickers]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4965a19f500f0cf1",
   "metadata": {},
   "source": [
    "df_completa = pd.DataFrame(dados_completos)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff5c509f3124e5c7",
   "metadata": {},
   "source": [
    "df_completa"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "719a0d4cea6b921c",
   "metadata": {},
   "source": [
    "df_completa.replace(\"N/A\", pd.NA, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f486b993abb804ae",
   "metadata": {},
   "source": [
    "# Extract the \"ticker_name\" list of rows removed due to NA values\n",
    "removed_tickers = df_completa.loc[df_completa[[\"sector\", \"sector_key\", \"industry\"]].isna().any(axis=1), \"ticker_name\"].tolist()\n",
    "\n",
    "# Drop rows with NA values in specified columns\n",
    "df_completa.dropna(subset=[\"sector\", \"sector_key\", \"industry\"], inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "38c5720a14463c74",
   "metadata": {},
   "source": [
    "df_completa[\"yahoo_ticker_information\"] = df_completa[\"yahoo_ticker_information\"].apply(lambda x: json.dumps(x) if isinstance(x, dict) else x)\n",
    "df_completa.to_sql(\"tickers\", sqlite3.connect(\"data/bancoDados.db\"), if_exists=\"replace\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51b1f51e9a55f604",
   "metadata": {},
   "source": [
    "df_completa"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ffe2e2be061ccb2",
   "metadata": {},
   "source": [
    "## Dados Cortados"
   ]
  },
  {
   "cell_type": "code",
   "id": "17d662d01893863b",
   "metadata": {},
   "source": [
    "tickers_cortados = [\n",
    "    *[{\"Ticker\":f, \"Motivo\":\"Não tinha informação quanto a setor\"} for f in removed_tickers],\n",
    "    *[{\"Ticker\":g, \"Motivo\":\"Não foi obtido informações, ticker_row da NYSE\"} for g in tickers_descartados],\n",
    "    *[{\"Ticker\":h, \"Motivo\":\"Não foi obtido informações, ticker_row da NASDAQ\"} for h in tickers_descartados_nasdaq]\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f6e62eb42359569",
   "metadata": {},
   "source": [
    "df_cortada = pd.DataFrame(tickers_cortados)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11c8735f1a886676",
   "metadata": {},
   "source": [
    "df_cortada.to_sql(\"tickers_cortados\", conn, if_exists=\"replace\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "75724daccd031672",
   "metadata": {},
   "source": [
    "## Obtendo Cotações"
   ]
  },
  {
   "cell_type": "code",
   "id": "4206ebd170c98460",
   "metadata": {},
   "source": [
    "df_tickers = pd.read_sql(\"\"\"SELECT ticker_name FROM tickers\"\"\", conn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a527f2f5c5fcd35",
   "metadata": {},
   "source": [
    "start_date = \"2014-01-01\"\n",
    "tickers_descartados_cotacao = []\n",
    "tickers_descartados_dividendo = []\n",
    "tickers_descartados_erro = []\n",
    "\n",
    "for ticker_row in tqdm(df_tickers['ticker_name'], desc=\"Processando Tickers\"):\n",
    "    stock = yf.Ticker(ticker_row)\n",
    "    # Cotações: Verifica se há dados e se cobrem mais de 10 anos\n",
    "    try:\n",
    "        prices = stock.history(\n",
    "                        start=start_date,\n",
    "                        interval=\"1d\",\n",
    "                        auto_adjust=False,\n",
    "                        back_adjust=False,\n",
    "                        raise_errors=True\n",
    "        ).reset_index()\n",
    "\n",
    "        if not prices.empty:\n",
    "            # Calcula os anos entre a primeira e a última data\n",
    "            start_year = prices['Date'].iloc[0].year\n",
    "            end_year = prices['Date'].iloc[-1].year\n",
    "            years_of_data = end_year - start_year\n",
    "\n",
    "            # Verifica se há menos de 10 anos de dados\n",
    "            if years_of_data < 10:\n",
    "                tickers_descartados_cotacao.append(ticker_row)\n",
    "                continue\n",
    "\n",
    "            if not(\"Dividends\" in prices.columns and (prices[\"Dividends\"] > 0).any()):\n",
    "                tickers_descartados_dividendo.append(ticker_row)\n",
    "                continue\n",
    "\n",
    "            # Se dados válidos, prossegue com o processamento\n",
    "            prices['ticker_name'] = ticker_row\n",
    "            prices.to_sql(\"prices\", conn, if_exists=\"append\", index=False)\n",
    "        else:\n",
    "            tickers_descartados_cotacao.append(ticker_row)\n",
    "            continue\n",
    "\n",
    "    except Exception as e:\n",
    "        tickers_descartados_erro.append(ticker_row)\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    time.sleep(0.3)  # Pausa para evitar sobrecarga na API\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "893bb2ad17a2fec5",
   "metadata": {},
   "source": [
    "tickers_descartados_df = pd.DataFrame(\n",
    "   [*[{\"Ticker\": f, \"Motivo\":\"Erro desconhecido na coleta de cotações\" } for f in tickers_descartados_erro],\n",
    "    *[{\"Ticker\": f, \"Motivo\":\"Empresa sem Dividendos nos ultimos 10 anos\" } for f in tickers_descartados_dividendo],\n",
    "    *[{\"Ticker\": f, \"Motivo\":\"Empresa com menos de  10 anos\" } for f in tickers_descartados_cotacao]],\n",
    "    columns=[\"Ticker\", \"Motivo\"]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4d5ae6701a5aa11",
   "metadata": {},
   "source": [
    "tickers_descartados_df.to_sql(\"tickers_cortados\", conn, if_exists=\"append\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9d707b2c3b1f1652",
   "metadata": {},
   "source": [
    "# Verificação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "id": "1fe30d76417d7efe",
   "metadata": {},
   "source": [
    "def contar_dividendos(ticker: str) -> int:\n",
    "    \"\"\"\n",
    "    Conta quantas vezes foram pagos dividendos para um determinado ticker_row dentro de um período.\n",
    "\n",
    "    Parâmetros:\n",
    "    - ticker_row (str): Código do ativo na bolsa (ex: \"AAPL\").\n",
    "    - data_inicio (str): Data de início no formato \"YYYY-MM-DD\".\n",
    "    - data_fim (str): Data de fim no formato \"YYYY-MM-DD\".\n",
    "\n",
    "    Retorna:\n",
    "    - int: Número de pagamentos de dividendos dentro do período.\n",
    "    \"\"\"\n",
    "    data_inicio = \"2014-01-01\"\n",
    "    data_fim = \"2025-03-06\"\n",
    "    # Baixa os dados do ativo\n",
    "    ativo = yf.Ticker(ticker)\n",
    "\n",
    "    # Obtém o histórico de dividendos\n",
    "    dividendos = ativo.dividends\n",
    "\n",
    "    if dividendos.empty:\n",
    "        print(f\"Nenhum dividendo encontrado para {ticker}.\")\n",
    "        return 0\n",
    "\n",
    "    # Filtra pelo período desejado\n",
    "    dividendos_periodo = dividendos.loc[data_inicio:data_fim]\n",
    "\n",
    "    # Retorna a contagem de pagamentos de dividendos\n",
    "    return len(dividendos_periodo)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad0150290de2a30e",
   "metadata": {},
   "source": [
    "df_verificacao = pd.read_sql(\"\"\"\n",
    "SELECT ticker_name, COUNT(*) AS dividend_count\n",
    "FROM prices\n",
    "WHERE Dividends != 0\n",
    "GROUP BY ticker_name\n",
    "\"\"\", conn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4608cd2d5170f0ef",
   "metadata": {},
   "source": [
    "df_verificacao['Verificacao'] = df_verificacao['ticker_name'].apply(contar_dividendos)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c52fe633fe24cbe3",
   "metadata": {},
   "source": [
    "df_verificacao[\"Validade\"] = df_verificacao['dividend_count'] == df_verificacao['Verificacao']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fde04d58ea823175",
   "metadata": {},
   "source": [
    "df_verificacao"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69504aeed18e8717",
   "metadata": {},
   "source": [
    "O banco está com todos os dados corretos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee892b4f9e5195",
   "metadata": {},
   "source": [
    "# Processamento"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotando numero de dividendos",
   "id": "9dcee9b53e8db0f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "WITH DividendCounts AS (\n",
    "    SELECT ticker_name, COUNT(*) AS dividend_count\n",
    "    FROM prices\n",
    "    WHERE Dividends != 0\n",
    "    GROUP BY ticker_name\n",
    ")\n",
    "SELECT X, COUNT(*) AS companies_above_X\n",
    "FROM (\n",
    "    SELECT DISTINCT dividend_count AS X FROM DividendCounts\n",
    ") AS Levels\n",
    "JOIN DividendCounts DC ON DC.dividend_count >= Levels.X\n",
    "GROUP BY X\n",
    "ORDER BY X;\n",
    "\"\"\"\n",
    "\n",
    "# Conectar ao banco e executar a query\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Criar o gráfico de densidade invertida\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.fill_between(df[\"X\"], df[\"companies_above_X\"], color='blue', alpha=0.3)\n",
    "plt.plot(df[\"X\"], df[\"companies_above_X\"], marker='o', linestyle='-', color='blue')\n",
    "plt.axvline(x=40, color='red', linestyle='-', alpha=0.8)\n",
    "plt.xlim(0, df[\"X\"].max())\n",
    "plt.ylim(0,df['companies_above_X'].max())\n",
    "# Configurar labels e título\n",
    "plt.xlabel(\"Quantidade de Empresas que Pagaram ≥ X Dividendos\")\n",
    "plt.ylabel(\"Empresas com X ou Mais Dividendos\")\n",
    "plt.title(\"Distribuição da Frequência de Pagamento de Dividendos\")\n",
    "for x in range(0, df[\"X\"].max() + 1, 5):\n",
    "    plt.axvline(x, color='red', linestyle='--', alpha=0.1)\n",
    "\n",
    "plt.axhline(y=0, color='black', linewidth=3)  # Linha horizontal no eixo X\n",
    "plt.axvline(x=0, color='black', linewidth=3)  # Linha vertical no eixo Y começando no X=1\n",
    "\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ],
   "id": "c2fd4592ab842710",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Percentual'] = df['companies_above_X'] / 2030 * 100",
   "id": "383746e744053ec1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f989d632474a1920",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_excel(\"Saidas/CompaniasComDividendos.xlsx\", index=False)",
   "id": "f06956e2251b46f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testes com Betas",
   "id": "cbbbe9469cc7e693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_lista_ativos = \"\"\"\n",
    "select DISTINCT(ticker_name)\n",
    "from prices;\n",
    "\"\"\""
   ],
   "id": "eb1895c2dd65fef7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cursor = None\n",
    "try:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query_lista_ativos)\n",
    "    lista_ativos_bruta = cursor.fetchall()\n",
    "    lista_ativos = [ativo[0] for ativo in lista_ativos_bruta]\n",
    "    print(lista_ativos[0:5])\n",
    "finally:\n",
    "    # Garantir o fechamento do cursor\n",
    "    cursor.close()\n"
   ],
   "id": "1ebf1b088533a943",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Teste Individual",
   "id": "f4d49f9fd13b825"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_cotacoes = \"\"\"\n",
    "SELECT *\n",
    "FROM prices\n",
    "WHERE ticker_name = :ticker_name\n",
    "ORDER BY Date asc;\n",
    "\"\"\""
   ],
   "id": "ceab3b9674536b97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    del df, df_dividends\n",
    "except:\n",
    "    pass"
   ],
   "id": "e1d5ae67b7b1f6f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params = {\"ticker_name\": \"AAPL\"}  # Substitua \"AAPL\" pelo ticker_row que deseja filtrar\n",
    "df = pd.read_sql_query(query_cotacoes, conn, params=params)"
   ],
   "id": "6481f9f1281860e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remover o fuso horário ANTES de converter para datetime\n",
    "df['Date'] = df['Date'].astype(str).str[:-6]  # Remove o \"-04:00\" ou qualquer fuso\n",
    "df['Date'] = pd.to_datetime(df['Date'])  # Agora converte sem erro\n",
    "df = df.sort_values('Date')"
   ],
   "id": "68e3feb1851f98da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar uma coluna com o Open do dia anterior (no df original)\n",
    "df[\"Close_Previous_Day\"] = df[\"Close\"].shift(1)\n",
    "\n",
    "df['R'] = df['Open'] / df['Close_Previous_Day'] - 1\n",
    "\n",
    "# Filtrar os dias onde houve pagamento de dividendos\n",
    "df_dividends = df[df[\"Dividends\"] != 0].copy()\n",
    "\n",
    "# Calcular a variação relativa ao montante distribuído\n",
    "df_dividends[\"Price_Drop_Per_Dividend\"] = (df_dividends[\"Close_Previous_Day\"] - df_dividends[\"Open\"]) / df_dividends[\"Dividends\"]\n",
    "\n"
   ],
   "id": "2d46a738f4649394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_dividends = df_dividends.dropna(subset=[\"Price_Drop_Per_Dividend\"])\n",
    "\n",
    "# Calcular estatísticas\n",
    "media = df_dividends[\"Price_Drop_Per_Dividend\"].mean()\n",
    "desvio_padrao = df_dividends[\"Price_Drop_Per_Dividend\"].std()\n",
    "\n",
    "# Criar o gráfico de densidade\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df_dividends[\"Price_Drop_Per_Dividend\"], fill=True, label=\"Densidade\")\n",
    "\n",
    "# Adicionar linhas da média e do desvio padrão\n",
    "plt.axvline(media, color='r', linestyle='dashed', linewidth=2, label=f'Média: {media:.4f}')\n",
    "plt.axvline(media + desvio_padrao, color='g', linestyle='dashed', linewidth=2, label=f'+1σ: {desvio_padrao:.4f}')\n",
    "plt.axvline(media - desvio_padrao, color='g', linestyle='dashed', linewidth=2, label=f'-1σ')\n",
    "\n",
    "# Configurar rótulos e título\n",
    "plt.xlabel(\"Price Drop Per Dividend\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribuição da Queda do Preço Relativa ao Dividendo\")\n",
    "plt.legend()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "6167fede3644cc8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar a figura e o eixo principal (esquerda)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotar a série \"Price_Drop_Per_Dividend\" no eixo da esquerda\n",
    "ax1.plot(df_dividends[\"Date\"], df_dividends[\"Price_Drop_Per_Dividend\"],\n",
    "         color='b', marker='o', linestyle='-', label=\"Price Drop Per Dividend\")\n",
    "ax1.set_xlabel(\"Data\")\n",
    "ax1.set_ylabel(\"Price Drop Per Dividend\", color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Criar o segundo eixo (direita) para \"Dividends\"\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_dividends[\"Date\"], df_dividends[\"Dividends\"],\n",
    "         color='r', marker='s', linestyle='--', label=\"Dividendo Distribuído\")\n",
    "ax2.set_ylabel(\"Dividendo Distribuído\", color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Melhorando o layout\n",
    "fig.tight_layout()\n",
    "plt.title(\"Evolução do Price Drop Per Dividend, Dividendo Distribuído e Preço da Ação\")\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "e4c4ba1eccf84342",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar a figura e o eixo principal (esquerda)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotar a série \"Price_Drop_Per_Dividend\" no eixo da esquerda\n",
    "ax1.plot(df_dividends[\"Date\"], df_dividends[\"Price_Drop_Per_Dividend\"],\n",
    "         color='b',  linestyle='-', label=\"Price Drop Per Dividend\")\n",
    "ax1.set_xlabel(\"Data\")\n",
    "ax1.set_ylabel(\"Price Drop Per Dividend\", color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Criar o segundo eixo (direita) para \"Dividends\"\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_dividends[\"Date\"], df_dividends[\"Dividends\"],\n",
    "         color='r', linestyle='--', label=\"Dividendo Distribuído\")\n",
    "ax2.set_ylabel(\"Dividendo Distribuído\", color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Criar um terceiro eixo para o preço da ação\n",
    "ax3 = ax1.twinx()\n",
    "ax3.spines['right'].set_position(('outward', 60))  # Deslocar para evitar sobreposição\n",
    "ax3.plot(df[\"Date\"], df[\"Close\"], color='g', linestyle='-', label=\"Preço de Fechamento\")\n",
    "ax3.set_ylabel(\"Preço de Fechamento\", color='g')\n",
    "ax3.tick_params(axis='y', labelcolor='g')\n",
    "\n",
    "# Melhorando o layout\n",
    "fig.tight_layout()\n",
    "plt.title(\"Evolução do Price Drop Per Dividend, Dividendo Distribuído, Preço da Ação e Volume\")\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "222fe74b01ae74e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar a figura e o eixo principal (esquerda)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotar a série \"Price_Drop_Per_Dividend\" no eixo da esquerda\n",
    "ax1.plot(df_dividends[\"Date\"], df_dividends[\"Price_Drop_Per_Dividend\"],\n",
    "         color='b',  linestyle='-', label=\"Price Drop Per Dividend\")\n",
    "ax1.set_xlabel(\"Data\")\n",
    "ax1.set_ylabel(\"Price Drop Per Dividend\", color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Criar o segundo eixo (direita) para \"Dividends\"\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_dividends[\"Date\"], df_dividends[\"Dividends\"],\n",
    "         color='r', linestyle='--', label=\"Dividendo Distribuído\")\n",
    "ax2.set_ylabel(\"Dividendo Distribuído\", color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Criar um terceiro eixo para o volume negociado\n",
    "ax3 = ax1.twinx()\n",
    "ax3.spines['right'].set_position(('outward', 60))  # Deslocar para evitar sobreposição\n",
    "ax3.bar(df[\"Date\"], df[\"Volume\"], color='g', alpha=0.3, label=\"Volume Negociado\")\n",
    "ax3.set_ylabel(\"Volume Negociado\", color='g')\n",
    "ax3.tick_params(axis='y', labelcolor='g')\n",
    "\n",
    "# Melhorando o layout\n",
    "fig.tight_layout()\n",
    "plt.title(\"Evolução do Price Drop Per Dividend, Dividendo Distribuído e Volume Negociado\")\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "ac0d9e907a05e57a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular o desvio padrão móvel de 30 dias do preço de fechamento\n",
    "df[\"Std_Close\"] = df[\"Close\"].rolling(window=30).std()\n",
    "\n",
    "# Criar a figura e o eixo principal (esquerda)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotar a série \"Price Drop Per Dividend\" no eixo da esquerda\n",
    "ax1.plot(df_dividends[\"Date\"], df_dividends[\"Price_Drop_Per_Dividend\"],\n",
    "         color='b', linestyle='-', label=\"Price Drop Per Dividend\")\n",
    "ax1.set_xlabel(\"Data\")\n",
    "ax1.set_ylabel(\"Price Drop Per Dividend\", color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Criar o segundo eixo (direita) para \"Dividends\"\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_dividends[\"Date\"], df_dividends[\"Dividends\"],\n",
    "         color='r', linestyle='--', label=\"Dividendo Distribuído\")\n",
    "ax2.set_ylabel(\"Dividendo Distribuído\", color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Criar um terceiro eixo para o desvio padrão do preço da ação\n",
    "ax3 = ax1.twinx()\n",
    "ax3.spines['right'].set_position(('outward', 60))  # Deslocar para evitar sobreposição\n",
    "ax3.plot(df[\"Date\"], df[\"Std_Close\"], color='g', linestyle='-', label=\"Desvio Padrão (30 dias)\")\n",
    "ax3.set_ylabel(\"Desvio Padrão do Preço (30 dias)\", color='g')\n",
    "ax3.tick_params(axis='y', labelcolor='g')\n",
    "\n",
    "# Melhorando o layout\n",
    "fig.tight_layout()\n",
    "plt.title(\"Evolução do Price Drop Per Dividend, Dividendo Distribuído e Desvio Padrão do Preço da Ação\")\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "63ed0c2c381b57ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar a figura e o eixo principal (esquerda)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotar a série \"Price Drop Per Dividend\" no eixo da esquerda\n",
    "ax1.plot(df_dividends[\"Date\"], df_dividends[\"Price_Drop_Per_Dividend\"],\n",
    "         color='b', linestyle='-', label=\"Price Drop Per Dividend\")\n",
    "ax1.set_xlabel(\"Data\")\n",
    "ax1.set_ylabel(\"Price Drop Per Dividend\", color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Criar o segundo eixo (direita) para \"Dividends\"\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_dividends[\"Date\"], df_dividends[\"Dividends\"],\n",
    "         color='r', linestyle='--', label=\"Dividendo Distribuído\")\n",
    "ax2.set_ylabel(\"Dividendo Distribuído\", color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Criar um terceiro eixo para \"R\", substituindo o desvio padrão\n",
    "ax3 = ax1.twinx()\n",
    "ax3.spines['right'].set_position(('outward', 60))  # Deslocar para evitar sobreposição\n",
    "ax3.plot(df[\"Date\"], df[\"R\"], color='g', linestyle='-', label=\"R\")\n",
    "ax3.set_ylabel(\"R\", color='g')\n",
    "ax3.tick_params(axis='y', labelcolor='g')\n",
    "\n",
    "# Melhorando o layout\n",
    "fig.tight_layout()\n",
    "plt.title(\"Evolução do Price Drop Per Dividend, Dividendo Distribuído e R\")\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "be2b9d23806a0cc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular estatísticas\n",
    "media_r = df[\"R\"].mean()\n",
    "desvio_padrao_r = df[\"R\"].std()\n",
    "contagem_r = len(df['R'])\n",
    "\n",
    "# Criar o gráfico de densidade\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df[\"R\"], fill=True, label=\"Densidade\")\n",
    "\n",
    "# Adicionar linhas da média e do desvio padrão\n",
    "plt.axvline(media_r, color='r', linestyle='dashed', linewidth=2, label=f'Média: {media_r:.4f}')\n",
    "plt.axvline(media_r + desvio_padrao_r, color='g', linestyle='dashed', linewidth=2, label=f'+1σ: {desvio_padrao_r:.4f}')\n",
    "plt.axvline(media_r - desvio_padrao_r, color='g', linestyle='dashed', linewidth=2, label=f'-1σ')\n",
    "\n",
    "# Configurar rótulos e título\n",
    "plt.xlabel(\"R\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(f\"Distribuição de R, amostra {contagem_r}\")\n",
    "plt.legend()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()\n"
   ],
   "id": "96ac050e73e91826",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular estatísticas\n",
    "media_r_filtered = df_dividends[\"R\"].mean()\n",
    "desvio_padrao_r_filtered = df_dividends[\"R\"].std()\n",
    "contagem = len(df_dividends[\"R\"])\n",
    "\n",
    "# Criar o gráfico de densidade\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df_dividends[\"R\"], fill=True, label=\"Densidade\")\n",
    "\n",
    "# Adicionar linhas da média e do desvio padrão\n",
    "plt.axvline(media_r_filtered, color='r', linestyle='dashed', linewidth=2, label=f'Média: {media_r_filtered:.4f}')\n",
    "plt.axvline(media_r_filtered + desvio_padrao_r_filtered, color='g', linestyle='dashed', linewidth=2, label=f'+1σ: {desvio_padrao_r_filtered:.4f}')\n",
    "plt.axvline(media_r_filtered - desvio_padrao_r_filtered, color='g', linestyle='dashed', linewidth=2, label=f'-1σ')\n",
    "\n",
    "# Configurar rótulos e título\n",
    "plt.xlabel(\"R\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(f\"Distribuição de R (Apenas quando Dividends ≠ 0) Amostra: {contagem}\")\n",
    "plt.legend()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "4db24bcb7d8da46a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular estatísticas\n",
    "df_filtered = df[df['Dividends'] == 0].copy()\n",
    "\n",
    "media_r_filtered = df_filtered[\"R\"].mean()\n",
    "desvio_padrao_r_filtered = df_filtered[\"R\"].std()\n",
    "contagem = len(df_filtered[\"R\"])\n",
    "\n",
    "# Criar o gráfico de densidade\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df_filtered[\"R\"], fill=True, label=\"Densidade\")\n",
    "\n",
    "# Adicionar linhas da média e do desvio padrão\n",
    "plt.axvline(media_r_filtered, color='r', linestyle='dashed', linewidth=2, label=f'Média: {media_r_filtered:.4f}')\n",
    "plt.axvline(media_r_filtered + desvio_padrao_r_filtered, color='g', linestyle='dashed', linewidth=2, label=f'+1σ: {desvio_padrao_r_filtered:.4f}')\n",
    "plt.axvline(media_r_filtered - desvio_padrao_r_filtered, color='g', linestyle='dashed', linewidth=2, label=f'-1σ')\n",
    "\n",
    "# Configurar rótulos e título\n",
    "plt.xlabel(\"R\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(f\"Distribuição de R (Apenas quando Dividends = 0) Amostra: {contagem}\")\n",
    "plt.legend()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "785f7038d530868d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# testes para verificar se são a mesma distribuição:\n",
    "R_global = df[\"R\"].dropna()\n",
    "R_divs = df_dividends[\"R\"].dropna()\n",
    "R_sem_divs = df_filtered[\"R\"].dropna()\n",
    "\n",
    "\n",
    "comparisons = {\n",
    "    (\"R_global\", \"R_divs\"): stats.ks_2samp(R_global, R_divs),\n",
    "    (\"R_global\", \"R_sem_divs\"): stats.ks_2samp(R_global, R_sem_divs),\n",
    "    (\"R_divs\", \"R_sem_divs\"): stats.ks_2samp(R_divs, R_sem_divs),\n",
    "}\n",
    "\n",
    "alpha = 0.05\n",
    "# Criando a matriz de resultados\n",
    "results_matrix = pd.DataFrame(index=[\"R_global\", \"R_divs\", \"R_sem_divs\"],\n",
    "                              columns=[\"R_global\", \"R_divs\", \"R_sem_divs\"])\n",
    "\n",
    "# Preenchendo a matriz com \"Diferente\" ou \"Igual\" conforme o valor-p do teste KS\n",
    "for (r1, r2), (statistic, p_value) in comparisons.items():\n",
    "    results_matrix.loc[r1, r2] = p_value\n",
    "    results_matrix.loc[r2, r1] = p_value  # Para manter simetria\n",
    "\n",
    "# Diagonal é sempre \"Igual\", pois está comparando a mesma distribuição\n",
    "np.fill_diagonal(results_matrix.values, 1)\n",
    "\n",
    "results_matrix"
   ],
   "id": "67a7910158560bf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "shapiro_stat, shapiro_p = stats.shapiro(R_divs)\n",
    "\n",
    "# Teste de Mann-Whitney U para comparar R_divs com os outros dois grupos\n",
    "mw_global_stat, mw_global_p = stats.mannwhitneyu(R_global, R_divs, alternative='two-sided')\n",
    "mw_sem_divs_stat, mw_sem_divs_p = stats.mannwhitneyu(R_sem_divs, R_divs, alternative='two-sided')\n",
    "\n",
    "# Criando tabela com os resultados\n",
    "test_results = pd.DataFrame({\n",
    "    \"Teste\": [\"Shapiro-Wilk (Normalidade R_divs)\",\n",
    "              \"Mann-Whitney U (R_global vs R_divs)\",\n",
    "              \"Mann-Whitney U (R_sem_divs vs R_divs)\"],\n",
    "    \"Estatística\": [shapiro_stat, mw_global_stat, mw_sem_divs_stat],\n",
    "    \"p-valor\": [shapiro_p, mw_global_p, mw_sem_divs_p],\n",
    "    \"Conclusão (alpha=0.05)\": [\"Rejeita H0 (Não Normal)\" if shapiro_p < 0.05 else \"Aceita H0 (Normal)\",\n",
    "                                \"Diferente\" if mw_global_p < 0.05 else \"Igual\",\n",
    "                                \"Diferente\" if mw_sem_divs_p < 0.05 else \"Igual\"]\n",
    "})\n",
    "test_results"
   ],
   "id": "4882a0a57a0d8a3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aplicando Testes em larga escala",
   "id": "9952251b8c44bc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for ativo in tqdm(lista_ativos):\n",
    "    params = {\"ticker_name\": ativo}  # Substitua \"AAPL\" pelo ticker_row que deseja filtrar\n",
    "    df = pd.read_sql_query(query_cotacoes, conn, params=params)\n",
    "\n",
    "    # Remover o fuso horário ANTES de converter para datetime\n",
    "    df['Date'] = df['Date'].astype(str).str[:-6]  # Remove o \"-04:00\" ou qualquer fuso\n",
    "    df['Date'] = pd.to_datetime(df['Date'])  # Agora converte sem erro\n",
    "    df = df.sort_values('Date')\n",
    "\n",
    "    # Criar uma coluna com o Open do dia anterior (no df original)\n",
    "    df[\"Close_Previous_Day\"] = df[\"Close\"].shift(1)\n",
    "\n",
    "    # Filtrar os dias onde houve pagamento de dividendos\n",
    "    df_dividends = df[df[\"Dividends\"] != 0].copy()\n",
    "\n",
    "    # Calcular a variação relativa ao montante distribuído\n",
    "    df_dividends[\"Price_Drop_Per_Dividend\"] = (df_dividends[\"Close_Previous_Day\"] - df_dividends[\"Open\"]) / df_dividends[\"Dividends\"]\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Selecionar apenas as colunas necessárias\n",
    "    df_to_insert = df_dividends[['Date', 'ticker_name', 'Price_Drop_Per_Dividend']].copy()\n",
    "\n",
    "    # Renomear colunas para coincidir com a tabela SQL\n",
    "    df_to_insert.rename(columns={'Price_Drop_Per_Dividend': 'value'}, inplace=True)\n",
    "\n",
    "    # Inserir no SQLite (modo append)\n",
    "    df_to_insert.to_sql('pre_test_dividends', conn, if_exists='append', index=False)\n",
    "\n",
    "    cursor.close()\n"
   ],
   "id": "7c011d81c9915eef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_pre_test_dividends = \"\"\"\n",
    "SELECT *\n",
    "FROM pre_test_dividends\n",
    "\"\"\""
   ],
   "id": "c81e0d9e3b80c6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_pre_test_dividends = pd.read_sql_query(query_pre_test_dividends, conn)\n",
    "df_pre_test_dividends['Date'] = pd.to_datetime(df_pre_test_dividends['Date'])"
   ],
   "id": "80dfa7feeab7c0f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Definindo os percentis desejados\n",
    "percentiles = [0, 1, 2.5, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 97.5, 99, 100]\n",
    "df_pre_test_dividends_clean = df_pre_test_dividends.dropna()\n",
    "\n",
    "# Calculando os valores estatísticos\n",
    "desc_stats = df_pre_test_dividends_clean['value'].describe()\n",
    "percentile_values = np.percentile(df_pre_test_dividends_clean['value'], percentiles)\n",
    "# Criando um DataFrame consolidado\n",
    "stats_df = pd.DataFrame({'Metric': ['count', 'mean', 'std'] + [f'{p}%' for p in percentiles],\n",
    "                         'Value': list(desc_stats)[:3] + list(percentile_values)})\n",
    "stats_df.to_excel(\"Saidas/StatsPreTestDividends.xlsx\", index=False)"
   ],
   "id": "e487e970dab16c49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_pre_test_dividends = df_pre_test_dividends.dropna(subset=[\"value\"])\n",
    "\n",
    "# Filtrar os valores extremos no intervalo de -10 a 10\n",
    "df_pre_test_dividends = df_pre_test_dividends[(df_pre_test_dividends[\"value\"] >= -10) & (df_pre_test_dividends[\"value\"] <= 10)]\n",
    "\n",
    "# Calcular estatísticas\n",
    "media = df_pre_test_dividends[\"value\"].mean()\n",
    "desvio_padrao = df_pre_test_dividends[\"value\"].std()\n",
    "\n",
    "# Criar o gráfico de densidade\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df_pre_test_dividends[\"value\"], fill=True, label=\"Densidade\", bw_adjust=1.2)\n",
    "\n",
    "# Adicionar linhas da média e do desvio padrão\n",
    "plt.axvline(media, color='r', linestyle='dashed', linewidth=2, label=f'Média: {media:.4f}')\n",
    "plt.axvline(media + desvio_padrao, color='g', linestyle='dashed', linewidth=2, label=f'+1σ: {desvio_padrao:.4f}')\n",
    "plt.axvline(media - desvio_padrao, color='g', linestyle='dashed', linewidth=2, label=f'-1σ')\n",
    "\n",
    "# Configurar rótulos e título\n",
    "plt.xlabel(\"Price Drop Per Dividend global\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlim(-10, 10)  # Limitar ao intervalo de -10 a 10\n",
    "plt.title(\"Distribuição da Queda do Preço Relativa ao Dividendo\")\n",
    "plt.legend()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "1f63556931a56188",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Agrupar os dados por semana para reduzir o ruído\n",
    "df_weekly = df_pre_test_dividends.groupby(pd.Grouper(key='Date', freq='W'))['value'] \\\n",
    "                                  .agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Plot dos dados: primeiro a linha do desvio padrão e depois a linha da média (para que fique por cima)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_weekly['Date'], df_weekly['mean'] + df_weekly['std'], color='blue', linestyle='--', linewidth=2, label='Desvio Padrão', zorder=3)\n",
    "plt.plot(df_weekly['Date'], df_weekly['mean'], color='red', linewidth=2, label='Média', zorder=5)\n",
    "plt.plot(df_weekly['Date'], df_weekly['mean'] - df_weekly['std'], color='blue', linestyle='--', linewidth=2, label='Desvio Padrão', zorder=3)\n",
    "\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Tendência da Média e Desvio Padrão (Agrupados Semanalmente)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5fa109534d13f067",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retorno Aftermarket",
   "id": "f963cabfc0f58609"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_r_sem_dividendos = \"\"\"\n",
    "with cotacoes AS (\n",
    "    SELECT ticker_name,\n",
    "         Date,\n",
    "         Open,\n",
    "         Close,\n",
    "         Dividends,\n",
    "         LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "    FROM prices\n",
    ")\n",
    "SELECT *, (c.Open / c.fechamento_ontem) - 1  as Diff\n",
    "FROM cotacoes as c\n",
    "where\n",
    "    fechamento_ontem IS NOT NULL\n",
    "    AND Dividends == 0;\n",
    "\"\"\""
   ],
   "id": "1003743d2a770055",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_r_global = pd.read_sql(query_r_sem_dividendos, conn)",
   "id": "9928d61287a12734",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular estatísticas\n",
    "df_filtered = df_r_global.copy()\n",
    "\n",
    "media_r_filtered = df_filtered[\"Diff\"].mean()\n",
    "desvio_padrao_r_filtered = df_filtered[\"Diff\"].std()\n",
    "contagem = len(df_filtered[\"Diff\"])\n",
    "\n",
    "# Criar o gráfico de densidade\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df_filtered[\"Diff\"], fill=True, bw_adjust=0.4, clip=(-0.05, 0.05))\n",
    "\n",
    "# Linha da média\n",
    "plt.axvline(media_r_filtered, color='red', linestyle='dashed', linewidth=2,\n",
    "            label=rf\"$\\mu$ = {media_r_filtered:.4f}\")\n",
    "\n",
    "# Linha de σ (sem deslocamento, apenas para legenda simbólica)\n",
    "plt.plot([], [], color='none', linestyle='solid', linewidth=1.5,\n",
    "         label=r\"$\\sigma$ = {:.4f}\".format(desvio_padrao_r_filtered))\n",
    "\n",
    "# Adicionar linhas para ±1σ, ±2σ, ±3σ com cores distintas\n",
    "cores = ['green', 'orange', 'purple']\n",
    "for i, cor in zip([1, 2, 3], cores):\n",
    "    plt.axvline(media_r_filtered + i * desvio_padrao_r_filtered, color=cor, linestyle='dotted', linewidth=1.5)\n",
    "    plt.axvline(media_r_filtered - i * desvio_padrao_r_filtered, color=cor, linestyle='dotted', linewidth=1.5)\n",
    "    plt.plot([], [], color=cor, linestyle='dotted', linewidth=1.5, label=fr\"$\\pm{i}\\sigma$\")\n",
    "\n",
    "# Ajustar limites\n",
    "plt.xlim(media_r_filtered - 3.5 * desvio_padrao_r_filtered, media_r_filtered + 3.5 * desvio_padrao_r_filtered)\n",
    "\n",
    "# Rótulos e título\n",
    "plt.xlabel(r\"$R_{am}$\")\n",
    "plt.ylabel(\"Densidade\")\n",
    "plt.title(fr\"Distribuição de $R_{{am}}$ apenas dias sem dividendos | Amostra: {contagem:,.0f}\".replace(\",\", \".\"))\n",
    "\n",
    "# Legenda ordenada no canto superior direito\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ],
   "id": "b4986dd3d4ddff1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Supondo que df_filtered[\"Diff\"] já esteja definido\n",
    "media = df_filtered[\"Diff\"].mean()\n",
    "desvio = df_filtered[\"Diff\"].std()\n",
    "n = len(df_filtered[\"Diff\"])\n",
    "\n",
    "# Estatística Z\n",
    "z = media / (desvio / np.sqrt(n))\n",
    "p_valor = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "\n",
    "print(f\"Z = {z:.4f}, p-valor = {p_valor:.10f}\")"
   ],
   "id": "68e4e1ecfe98c60f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "d = media / desvio\n",
    "print(f\"Cohen's d: {d:.4f}\")\n"
   ],
   "id": "e10a8bd1a82eb6c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_r_com_dividendos = \"\"\"\n",
    "with cotacoes AS (\n",
    "    SELECT ticker_name,\n",
    "         Date,\n",
    "         Open,\n",
    "         Close,\n",
    "         Dividends,\n",
    "         LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "    FROM prices\n",
    ")\n",
    "SELECT *, (c.Open / c.fechamento_ontem) - 1  as Diff\n",
    "FROM cotacoes as c\n",
    "where\n",
    "    fechamento_ontem IS NOT NULL\n",
    "    AND Dividends != 0;\n",
    "\"\"\"\n",
    "\n",
    "df_r_global_div = pd.read_sql(query_r_com_dividendos, conn)"
   ],
   "id": "8f84de9be2d54ff8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular estatísticas\n",
    "df_filtered_div = df_r_global_div.copy()\n",
    "\n",
    "media_r_filtered = df_filtered_div[\"Diff\"].mean()\n",
    "desvio_padrao_r_filtered = df_filtered_div[\"Diff\"].std()\n",
    "contagem = len(df_filtered_div[\"Diff\"])\n",
    "\n",
    "# Criar o gráfico de densidade\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df_filtered_div[\"Diff\"], fill=True, bw_adjust=0.4, clip=(-0.05, 0.05))\n",
    "\n",
    "# Linha da média\n",
    "plt.axvline(media_r_filtered, color='red', linestyle='dashed', linewidth=2,\n",
    "            label=rf\"$\\mu$ = {media_r_filtered:.4f}\")\n",
    "\n",
    "# Linha de σ (sem deslocamento, apenas para legenda simbólica)\n",
    "plt.plot([], [], color='none', linestyle='solid', linewidth=1.5,\n",
    "         label=r\"$\\sigma$ = {:.4f}\".format(desvio_padrao_r_filtered))\n",
    "\n",
    "# Adicionar linhas para ±1σ, ±2σ, ±3σ com cores distintas\n",
    "cores = ['green', 'orange', 'purple']\n",
    "for i, cor in zip([1, 2, 3], cores):\n",
    "    plt.axvline(media_r_filtered + i * desvio_padrao_r_filtered, color=cor, linestyle='dotted', linewidth=1.5)\n",
    "    plt.axvline(media_r_filtered - i * desvio_padrao_r_filtered, color=cor, linestyle='dotted', linewidth=1.5)\n",
    "    plt.plot([], [], color=cor, linestyle='dotted', linewidth=1.5, label=fr\"$\\pm{i}\\sigma$\")\n",
    "\n",
    "# Ajustar limites\n",
    "plt.xlim(media_r_filtered - 3.5 * desvio_padrao_r_filtered, media_r_filtered + 3.5 * desvio_padrao_r_filtered)\n",
    "\n",
    "# Rótulos e título\n",
    "plt.xlabel(r\"$R_{am}$\")\n",
    "plt.ylabel(\"Densidade\")\n",
    "plt.title(fr\"Distribuição de $R_{{am}}$ apenas dias com dividendos | Amostra: {contagem:,.0f}\".replace(\",\", \".\"))\n",
    "\n",
    "# Legenda ordenada no canto superior direito\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()\n"
   ],
   "id": "e4fcef09c910dd92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Supondo que df_filtered[\"Diff\"] já esteja definido\n",
    "media = df_filtered_div[\"Diff\"].mean()\n",
    "desvio = df_filtered_div[\"Diff\"].std()\n",
    "n = len(df_filtered_div[\"Diff\"])\n",
    "\n",
    "# Estatística Z\n",
    "z = media / (desvio / np.sqrt(n))\n",
    "p_valor = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "\n",
    "print(f\"Z = {z:.4f}, p-valor = {p_valor:.10f}\")\n",
    "\n",
    "d = media / desvio\n",
    "print(f\"Cohen's d: {d:.4f}\")\n"
   ],
   "id": "77f7a13a2d079050",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular estatísticas para Dividendos != 0\n",
    "df_filtered_div = df_r_global_div.copy()\n",
    "media_r_div = df_filtered_div[\"Diff\"].mean()\n",
    "desvio_padrao_r_div = df_filtered_div[\"Diff\"].std()\n",
    "contagem_div = len(df_filtered_div[\"Diff\"])\n",
    "\n",
    "# Calcular estatísticas para Dividendos = 0\n",
    "df_filtered = df_r_global.copy()\n",
    "media_r = df_filtered[\"Diff\"].mean()\n",
    "desvio_padrao_r = df_filtered[\"Diff\"].std()\n",
    "contagem = len(df_filtered[\"Diff\"])\n",
    "\n",
    "# Criar os gráficos de densidade lado a lado para comparação\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.kdeplot(df_filtered_div[\"Diff\"], fill=True, label=f\"Dividendos ≠ 0 (n={contagem_div})\", bw_adjust=0.5, clip=(-0.05, 0.05))\n",
    "sns.kdeplot(df_filtered[\"Diff\"], fill=True, label=f\"Dividendos = 0 (n={contagem})\", bw_adjust=0.5, clip=(-0.05, 0.05))\n",
    "\n",
    "# Adicionar linhas das médias\n",
    "plt.axvline(media_r_div, color='r', linestyle='dashed', linewidth=2, label=f'Média (Div ≠ 0): {media_r_div:.4f}')\n",
    "plt.axvline(media_r, color='b', linestyle='dashed', linewidth=2, label=f'Média (Div = 0): {media_r:.4f}')\n",
    "\n",
    "# Ajustar limites dos eixos\n",
    "xmin = min(media_r_div - 3*desvio_padrao_r_div, media_r - 3*desvio_padrao_r)\n",
    "xmax = max(media_r_div + 3*desvio_padrao_r_div, media_r + 3*desvio_padrao_r)\n",
    "plt.xlim(xmin, xmax)\n",
    "\n",
    "# Configurar rótulos e título\n",
    "plt.xlabel(r\"$R_{am}$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Comparação da Distribuição de $R_{am}$: Dividendos ≠ 0 vs Dividendos = 0\")\n",
    "plt.legend()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ],
   "id": "2586290e5f2eccb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testes quanto ao R",
   "id": "5839b2caa5a64e4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### o sem dividendo é um ruido branco?",
   "id": "345fcde23bf50229"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def testar_ruido_branco_ticker(ticker, conn, query, significance=0.05, lag=10):\n",
    "    \"\"\"\n",
    "    Testa se a série de tempo de uma companhia (coluna \"Diff\") é ruído branco.\n",
    "\n",
    "    Critérios testados:\n",
    "      1. Média zero (teste t de uma amostra);\n",
    "      2. Variância constante (teste ARCH);\n",
    "      3. Ausência de autocorrelação (Ljung-Box e Box-Pierce);\n",
    "      4. Autocorrelação de primeira ordem (teste Durbin-Watson);\n",
    "      5. Estacionaridade (teste Augmented Dickey-Fuller).\n",
    "\n",
    "    Parâmetros:\n",
    "      - ticker_row: (str) nome do ativo.\n",
    "      - conn: conexão com o banco de dados.\n",
    "      - query: query SQL que aceita um parâmetro para o ticker_row.\n",
    "      - significance: nível de significância para os testes (default 0.05).\n",
    "      - lag: número de lags para os testes.\n",
    "\n",
    "    Retorna:\n",
    "      Um dicionário com os resultados e as decisões de cada teste, incluindo uma decisão global.\n",
    "    \"\"\"\n",
    "\n",
    "    result_dict = {\"ticker_row\": ticker}\n",
    "\n",
    "    # Busca os dados para o ticker_row\n",
    "    try:\n",
    "        df_company = pd.read_sql(query, conn, params=[ticker])\n",
    "    except Exception as e:\n",
    "        result_dict[\"error\"] = f\"Erro na consulta: {e}\"\n",
    "        return result_dict\n",
    "\n",
    "    # Verifica se a coluna \"Diff\" existe\n",
    "    if \"Diff\" not in df_company.columns:\n",
    "        result_dict[\"error\"] = \"Coluna 'Diff' não encontrada\"\n",
    "        return result_dict\n",
    "\n",
    "    diff = df_company[\"Diff\"].dropna()\n",
    "\n",
    "    # Verifica se há dados suficientes para os testes\n",
    "    if len(diff) < lag:\n",
    "        result_dict[\"error\"] = \"Dados insuficientes\"\n",
    "        return result_dict\n",
    "\n",
    "    # 1. Teste de média zero (teste t de uma amostra)\n",
    "    t_stat, t_pvalue = ttest_1samp(diff, popmean=0)\n",
    "    result_dict[\"mean_stat\"] = t_stat\n",
    "    result_dict[\"mean_pvalue\"] = t_pvalue\n",
    "    result_dict[\"mean_decision\"] = \"ruido branco\" if t_pvalue > significance else \"não ruido branco\"\n",
    "\n",
    "    # 2. Teste de variância constante (homocedasticidade) – Teste ARCH\n",
    "    arch_stat, arch_pvalue, arch_f, arch_f_pvalue = het_arch(diff, nlags=lag)\n",
    "    result_dict[\"arch_stat\"] = arch_stat\n",
    "    result_dict[\"arch_pvalue\"] = arch_pvalue\n",
    "    result_dict[\"arch_decision\"] = \"ruido branco\" if arch_pvalue > significance else \"não ruido branco\"\n",
    "\n",
    "    # 3. Testes de autocorrelação – Ljung-Box e Box-Pierce\n",
    "    lb_result = acorr_ljungbox(diff, lags=[lag], return_df=True, boxpierce=True)\n",
    "    lb_stat = lb_result[\"lb_stat\"].iloc[-1]\n",
    "    lb_pvalue = lb_result[\"lb_pvalue\"].iloc[-1]\n",
    "    bp_stat = lb_result[\"bp_stat\"].iloc[-1]\n",
    "    bp_pvalue = lb_result[\"bp_pvalue\"].iloc[-1]\n",
    "    result_dict[\"lb_stat\"] = lb_stat\n",
    "    result_dict[\"lb_pvalue\"] = lb_pvalue\n",
    "    result_dict[\"bp_stat\"] = bp_stat\n",
    "    result_dict[\"bp_pvalue\"] = bp_pvalue\n",
    "    result_dict[\"acorr_decision\"] = \"ruido branco\" if (lb_pvalue > significance and bp_pvalue > significance) else \"não ruido branco\"\n",
    "\n",
    "    # 4. Teste Durbin-Watson (autocorrelação de primeira ordem)\n",
    "    dw_stat = durbin_watson(diff)\n",
    "    result_dict[\"dw_stat\"] = dw_stat\n",
    "    # Considera \"ruido branco\" se o valor estiver aproximadamente em 2 (ex.: entre 1.5 e 2.5)\n",
    "    result_dict[\"dw_decision\"] = \"ruido branco\" if 1.5 < dw_stat < 2.5 else \"não ruido branco\"\n",
    "\n",
    "    # 5. Teste de estacionaridade – Augmented Dickey-Fuller\n",
    "    adf_result = adfuller(diff, autolag='AIC', maxlag=lag)\n",
    "    adf_stat, adf_pvalue, usedlag, nobs, crit_values, icbest = adf_result\n",
    "    result_dict[\"adf_stat\"] = adf_stat\n",
    "    result_dict[\"adf_pvalue\"] = adf_pvalue\n",
    "    # Se p-valor < significance, rejeita a hipótese nula de raiz unitária (ou seja, é estacionária)\n",
    "    result_dict[\"adf_decision\"] = \"ruido branco\" if adf_pvalue < significance else \"não ruido branco\"\n",
    "\n",
    "    # Decisão global: somente se TODOS os testes indicarem ruido branco\n",
    "    if (result_dict[\"mean_decision\"]==\"ruido branco\" and\n",
    "        result_dict[\"arch_decision\"]==\"ruido branco\" and\n",
    "        result_dict[\"acorr_decision\"]==\"ruido branco\" and\n",
    "        result_dict[\"dw_decision\"]==\"ruido branco\" and\n",
    "        result_dict[\"adf_decision\"]==\"ruido branco\"):\n",
    "        overall = \"ruido branco\"\n",
    "    else:\n",
    "        overall = \"não ruido branco\"\n",
    "    result_dict[\"overall_decision\"] = overall\n",
    "\n",
    "    return result_dict\n"
   ],
   "id": "ee5c09f6c748cb10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_r_ticker = \"\"\"\n",
    "with cotacoes AS (\n",
    "    SELECT ticker_name,\n",
    "         Date,\n",
    "         Open,\n",
    "         Close,\n",
    "         Dividends,\n",
    "         LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "    FROM prices\n",
    ")\n",
    "SELECT *, (c.Open / c.fechamento_ontem) - 1  as Diff\n",
    "FROM cotacoes as c\n",
    "where\n",
    "    fechamento_ontem IS NOT NULL\n",
    "    AND Dividends == 0 AND\n",
    "    ticker_name == ?;\n",
    "\"\"\"\n",
    "\n",
    "query_tickers = \"\"\"\n",
    "SELECT\n",
    "    DISTINCT ticker_name\n",
    "FROM prices;\n",
    "\"\"\""
   ],
   "id": "8c6a3b5c1b61ab6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_tickers = pd.read_sql(query_tickers, conn)",
   "id": "60136f5d6428615c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_tickers_result = df_tickers.copy()",
   "id": "a08b8aba24605042",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_tickers_result = df_tickers_result['ticker_name'].apply(\n",
    "    lambda t: pd.Series(testar_ruido_branco_ticker(t, conn, query_r_com_dividendos))\n",
    ")"
   ],
   "id": "cadbc197301ddc14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_results_ruido = pd.DataFrame()\n",
    "criterios = [\"mean_decision\", \"arch_decision\", \"acorr_decision\", \"dw_decision\", \"adf_decision\", \"overall_decision\"]\n",
    "for crit in criterios:\n",
    "    df_results_ruido[crit] = df_tickers_result[crit].value_counts()\n",
    "\n",
    "df_results_ruido = df_results_ruido.T\n",
    "df_results_ruido.columns.name = \"Decisões\""
   ],
   "id": "2da0d43866e50fc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_results_ruido",
   "id": "54086fcfd2931232",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### `mean_decision` - Teste de Média Zero\n",
    "Verifica se a média da série é estatisticamente zero. Se não for, pode indicar tendência (drift).\n",
    "\n",
    "#### `arch_decision` - Teste ARCH (Heterocedasticidade)\n",
    "Testa se a variância da série é constante ao longo do tempo. Se variar, a volatilidade não é estável.\n",
    "\n",
    "#### `acorr_decision` - Teste de Autocorrelação\n",
    "Usa Ljung-Box e Box-Pierce para verificar dependência temporal. Se houver, a série tem memória.\n",
    "\n",
    "#### `dw_decision` - Teste de Durbin-Watson\n",
    "Avalia autocorrelação de primeira ordem. Valores próximos de 2 indicam ausência de dependência.\n",
    "\n",
    "#### `adf_decision` - Teste ADF (Estacionaridade)\n",
    "Verifica se a série tem raiz unitária. Se rejeitar a hipótese nula, a série é estacionária.\n",
    "\n",
    "#### `overall_decision` - Decisão Final\n",
    "A série só é ruído branco se passar em todos os testes. Se falhar em algum, tem padrão detectável.\n"
   ],
   "id": "3543168782fe6203"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_tickers_result.describe()",
   "id": "764e3229ec0d6aac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dados\n",
    "data_mean = df_tickers_result['mean_pvalue'].dropna().values\n",
    "density_mean = gaussian_kde(data_mean)\n",
    "x_mean = np.linspace(0, 1, 1000)\n",
    "y_mean = density_mean(x_mean)\n",
    "y_max_mean = y_mean.max()\n",
    "\n",
    "# Configuração do gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data_mean, fill=True, color='blue')\n",
    "\n",
    "# Linhas e Regiões Críticas\n",
    "plt.axvline(0.05, color='black', linestyle='--', linewidth=1.5, label='Valor Crítico = 0.05')\n",
    "plt.axvspan(0, 0.05, color='red', alpha=0.3, label='Rejeita H0 (p < 0.05) → Indica Tendência (Drift)')\n",
    "plt.axvspan(0.05, 1, color='green', alpha=0.2, label='Aceita H0 (p ≥ 0.05) → Sem Tendência')\n",
    "\n",
    "# Rótulos e Estilização\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, y_max_mean * 1.1)\n",
    "plt.title(\"Teste de Média Zero\\nVerificação de Tendência (Drift) na Série Temporal\", fontsize=14)\n",
    "plt.xlabel(\"P-Valor\", fontsize=12)\n",
    "plt.ylabel(\"Densidade\", fontsize=12)\n",
    "\n",
    "# Explicação das Hipóteses\n",
    "plt.text(0.15, y_max_mean * 0.9, \"H0: A média da série é estatisticamente zero\\n→ Não há tendência detectável\", fontsize=11, color='black')\n",
    "plt.text(0.15, y_max_mean * 0.8, \"H1: A média da série NÃO é zero\\n→ Existe tendência (drift)\", fontsize=11, color='black')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ],
   "id": "a0c717d69c228ed7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dados\n",
    "data_arch = df_tickers_result['arch_pvalue'].dropna().values\n",
    "density_arch = gaussian_kde(data_arch)\n",
    "x_arch = np.linspace(0, 1, 1000)\n",
    "y_arch = density_arch(x_arch)\n",
    "y_max_arch = y_arch.max()\n",
    "\n",
    "# Configuração do gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data_arch, fill=True, color='blue')\n",
    "\n",
    "# Linhas e Regiões Críticas\n",
    "plt.axvline(0.05, color='black', linestyle='--', linewidth=1.5, label='Valor Crítico = 0.05')\n",
    "plt.axvspan(0, 0.05, color='red', alpha=0.3, label='Rejeita H0 (p < 0.05) → Variância NÃO é constante')\n",
    "plt.axvspan(0.05, 1, color='green', alpha=0.2, label='Aceita H0 (p ≥ 0.05) → Variância constante')\n",
    "\n",
    "# Rótulos e Estilização\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, y_max_arch * 1.1)\n",
    "plt.title(\"Teste ARCH - Heterocedasticidade\\nVerificação da Estabilidade da Variância\", fontsize=14)\n",
    "plt.xlabel(\"P-Valor\", fontsize=12)\n",
    "plt.ylabel(\"Densidade\", fontsize=12)\n",
    "\n",
    "# Explicação das Hipóteses\n",
    "plt.text(0.15, y_max_arch * 0.9, \"H0: A variância da série é constante\\n→ Volatilidade estável\", fontsize=11, color='black')\n",
    "plt.text(0.15, y_max_arch * 0.8, \"H1: A variância da série NÃO é constante\\n→ Volatilidade instável (Heterocedasticidade)\", fontsize=11, color='black')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ],
   "id": "b322cbbe29f9b0db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dados\n",
    "data_lb = df_tickers_result['lb_pvalue'].dropna().values\n",
    "density_lb = gaussian_kde(data_lb)\n",
    "x_lb = np.linspace(0, 1, 1000)\n",
    "y_lb = density_lb(x_lb)\n",
    "y_max_lb = y_lb.max()\n",
    "\n",
    "# Configuração do gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data_lb, fill=True, color='blue')\n",
    "\n",
    "# Linhas e Regiões Críticas\n",
    "plt.axvline(0.05, color='black', linestyle='--', linewidth=1.5, label='Valor Crítico = 0.05')\n",
    "plt.axvspan(0, 0.05, color='red', alpha=0.3, label='Rejeita H0 (p < 0.05) → Existe autocorrelação')\n",
    "plt.axvspan(0.05, 1, color='green', alpha=0.2, label='Aceita H0 (p ≥ 0.05) → Sem autocorrelação')\n",
    "\n",
    "# Rótulos e Estilização\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, y_max_lb * 1.1)\n",
    "plt.title(\"Teste de Autocorrelação - Ljung-Box\\nVerificação de Dependência Temporal\", fontsize=14)\n",
    "plt.xlabel(\"P-Valor\", fontsize=12)\n",
    "plt.ylabel(\"Densidade\", fontsize=12)\n",
    "\n",
    "# Explicação das Hipóteses\n",
    "plt.text(0.15, y_max_lb * 0.9, \"H0: A série NÃO tem autocorrelação\\n→ Valores independentes ao longo do tempo\", fontsize=11, color='black')\n",
    "plt.text(0.15, y_max_lb * 0.8, \"H1: A série TEM autocorrelação\\n→ Existe dependência temporal (memória)\", fontsize=11, color='black')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ],
   "id": "94e6b01e71d1d06a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_bp = df_tickers_result['bp_pvalue'].dropna().values\n",
    "density_bp = gaussian_kde(data_bp)\n",
    "x_bp = np.linspace(0, 1, 1000)\n",
    "y_bp = density_bp(x_bp)\n",
    "y_max_bp = y_bp.max()\n",
    "\n",
    "# Configuração do gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data_bp, fill=True, color='blue')\n",
    "\n",
    "# Linhas e Regiões Críticas\n",
    "plt.axvline(0.05, color='black', linestyle='--', linewidth=1.5, label='Valor Crítico = 0.05')\n",
    "plt.axvspan(0, 0.05, color='red', alpha=0.3, label='Rejeita H0 (p < 0.05) → Existe autocorrelação')\n",
    "plt.axvspan(0.05, 1, color='green', alpha=0.2, label='Aceita H0 (p ≥ 0.05) → Sem autocorrelação')\n",
    "\n",
    "# Rótulos e Estilização\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, y_max_bp * 1.1)\n",
    "plt.title(\"Teste de Autocorrelação - Box-Pierce\\nVerificação de Dependência Temporal\", fontsize=14)\n",
    "plt.xlabel(\"P-Valor\", fontsize=12)\n",
    "plt.ylabel(\"Densidade\", fontsize=12)\n",
    "\n",
    "# Explicação das Hipóteses\n",
    "plt.text(0.15, y_max_bp * 0.9, \"H0: A série NÃO tem autocorrelação\\n→ Valores independentes ao longo do tempo\", fontsize=11, color='black')\n",
    "plt.text(0.15, y_max_bp * 0.8, \"H1: A série TEM autocorrelação\\n→ Existe dependência temporal (memória)\", fontsize=11, color='black')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ],
   "id": "f554f9b0d5033b42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dados\n",
    "data_adf = df_tickers_result['adf_pvalue'].dropna().values\n",
    "\n",
    "# Aplicando jitter para espalhar os dados (pequena variação aleatória)\n",
    "jitter_strength = 0.02  # Ajuste fino para não distorcer os dados\n",
    "data_adf_jittered = np.clip(data_adf + np.random.uniform(-jitter_strength, jitter_strength, len(data_adf)), 0, 1)\n",
    "\n",
    "# Estimando densidade\n",
    "density_adf = gaussian_kde(data_adf_jittered, bw_method=0.2)  # Aumenta a suavização\n",
    "x_adf = np.linspace(0, 1, 1000)\n",
    "y_adf = density_adf(x_adf)\n",
    "y_max_adf = y_adf.max()\n",
    "\n",
    "# Configuração do gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot KDE e histograma\n",
    "sns.histplot(data_adf_jittered, bins=30, kde=False, color=\"lightgray\", alpha=0.6, label=\"Histograma\")\n",
    "sns.kdeplot(data_adf_jittered, fill=True, color='blue', linewidth=2, bw_adjust=0.5)\n",
    "\n",
    "# Linhas e Regiões Críticas\n",
    "plt.axvline(0.05, color='black', linestyle='--', linewidth=1.5, label='Valor Crítico = 0.05')\n",
    "plt.axvspan(0, 0.05, color='red', alpha=0.3, label='Rejeita H0 (p < 0.05) → Série Estacionária')\n",
    "plt.axvspan(0.05, 1, color='green', alpha=0.2, label='Aceita H0 (p ≥ 0.05) → Série NÃO Estacionária')\n",
    "\n",
    "# Rótulos e Estilização\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, y_max_adf * 1.2)\n",
    "plt.title(\"Teste ADF - Estacionaridade\\nVerificação da Raiz Unitária na Série Temporal\", fontsize=14)\n",
    "plt.xlabel(\"P-Valor\", fontsize=12)\n",
    "plt.ylabel(\"Densidade\", fontsize=12)\n",
    "\n",
    "# Explicação das Hipóteses\n",
    "plt.text(0.15, y_max_adf * 0.9, \"H0: A série TEM raiz unitária\\n→ NÃO é estacionária\", fontsize=11, color='black')\n",
    "plt.text(0.15, y_max_adf * 0.8, \"H1: A série NÃO tem raiz unitária\\n→ É estacionária\", fontsize=11, color='black')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ],
   "id": "41ef04872848d827",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# df_tickers_result.to_sql(\"analise_ruido\", conn, if_exists=\"append\")",
   "id": "525aaaad11fba64f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aprimoramento do beta",
   "id": "e2b2eacb67e967a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Beta Regressão",
   "id": "74be65712c9169bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_cotacoes_por_ativo = \"\"\"\n",
    "with cotacoes AS (\n",
    "    SELECT\n",
    "        ticker_name,\n",
    "         Date,\n",
    "         Open,\n",
    "         Close,\n",
    "         Dividends,\n",
    "         LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "    FROM prices\n",
    ")\n",
    "SELECT *\n",
    "FROM cotacoes as c\n",
    "where\n",
    "    fechamento_ontem IS NOT NULL AND\n",
    "    ticker_name == ?;\n",
    "\"\"\"\n",
    "\n",
    "def regressao_dividendos(ticker_name):\n",
    "    \"\"\"\n",
    "    Roda a regressão para um ativo específico e retorna os principais indicadores em um dicionário.\n",
    "\n",
    "    Parâmetros:\n",
    "    - ticker_name (str): Código do ativo.\n",
    "    - conn: Conexão com o banco de dados.\n",
    "\n",
    "    Retorna:\n",
    "    - dict com coeficientes, métricas de ajuste, testes estatísticos e detecção de outliers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Consulta os dados do ativo\n",
    "    query = \"\"\"\n",
    "    with cotacoes AS (\n",
    "        SELECT\n",
    "             ticker_name,\n",
    "             Date,\n",
    "             Open,\n",
    "             Close,\n",
    "             Dividends,\n",
    "             LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "        FROM prices\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM cotacoes as c\n",
    "    where\n",
    "        fechamento_ontem IS NOT NULL AND\n",
    "        ticker_name == ? AND\n",
    "        Dividends != 0;\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, conn, params=[ticker_name])\n",
    "\n",
    "    # # Filtra apenas os dias com dividendos\n",
    "    # df = df[df[\"Dividends\"] != 0]\n",
    "\n",
    "    # Variável dependente: retorno ajustado\n",
    "    y_ajustado = df[\"Open\"] - df[\"fechamento_ontem\"]\n",
    "\n",
    "    # Variável independente: dividendos + constante\n",
    "    X = df[[\"Dividends\"]]\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Regressão OLS\n",
    "    modelo = sm.OLS(y_ajustado, X).fit()\n",
    "\n",
    "    # Influência e diagnóstico de outliers\n",
    "    influence = modelo.get_influence()\n",
    "    cooks_d = influence.cooks_distance[0]\n",
    "    max_cooks = np.max(cooks_d)\n",
    "    indice_outlier = int(np.argmax(cooks_d))\n",
    "    outlier_flag = max_cooks > 4 / len(df)\n",
    "\n",
    "    # Teste de normalidade dos resíduos\n",
    "    jb_stat, jb_p = jarque_bera(modelo.resid)\n",
    "\n",
    "    # Durbin-Watson para autocorrelação dos resíduos\n",
    "    durbin = sm.stats.stattools.durbin_watson(modelo.resid)\n",
    "\n",
    "    if modelo.model.exog.shape[1] >= 2:\n",
    "        bp_test = het_breuschpagan(modelo.resid, modelo.model.exog)\n",
    "        bp_stat, bp_pvalue = bp_test[0], bp_test[1]\n",
    "\n",
    "        white_test = het_white(modelo.resid, modelo.model.exog)\n",
    "        white_stat, white_pvalue = white_test[0], white_test[1]\n",
    "    else:\n",
    "        bp_stat, bp_pvalue = np.nan, np.nan\n",
    "        white_stat, white_pvalue = np.nan, np.nan\n",
    "\n",
    "    # Percentis dos resíduos\n",
    "    residuos = modelo.resid\n",
    "    p2_5 = np.percentile(residuos, 2.5)\n",
    "    p25 = np.percentile(residuos, 25)\n",
    "    p50 = np.percentile(residuos, 50)\n",
    "    p75 = np.percentile(residuos, 75)\n",
    "    p97_5 = np.percentile(residuos, 97.5)\n",
    "    extremos = np.sum((residuos < p2_5) | (residuos > p97_5))\n",
    "\n",
    "    # Resultados principais\n",
    "    resultados = {\n",
    "        \"ticker_name\": ticker_name,\n",
    "        \"alfa\": modelo.params[\"const\"] if \"const\" in modelo.params else None,\n",
    "        \"beta_dividendo\": modelo.params[\"Dividends\"],\n",
    "        \"erro_alfa\": modelo.bse[\"const\"] if \"const\" in modelo.params else None,\n",
    "        \"erro_beta\": modelo.bse[\"Dividends\"],\n",
    "        \"significancia_alfa\": modelo.pvalues[\"const\"] if \"const\" in modelo.params else None,\n",
    "        \"significancia_beta\": modelo.pvalues[\"Dividends\"],\n",
    "        \"r2\": modelo.rsquared,\n",
    "        \"r2_ajustado\": modelo.rsquared_adj,\n",
    "        \"f_stat\": modelo.fvalue,\n",
    "        \"p_f_stat\": modelo.f_pvalue,\n",
    "        \"durbin_watson\": durbin,\n",
    "        \"jarque_bera\": jb_stat,\n",
    "        \"p_jarque_bera\": jb_p,\n",
    "        \"breusch_pagan_stat\": bp_stat,\n",
    "        \"breusch_pagan_pvalue\": bp_pvalue,\n",
    "        \"white_stat\": white_stat,\n",
    "        \"white_pvalue\": white_pvalue,\n",
    "        \"max_cooks_distance\": max_cooks,\n",
    "        \"indice_outlier\": indice_outlier,\n",
    "        \"possui_outlier_influente\": outlier_flag,\n",
    "        \"residuo_p2_5\": p2_5,\n",
    "        \"residuo_p25\": p25,\n",
    "        \"residuo_p50\": p50,\n",
    "        \"residuo_p75\": p75,\n",
    "        \"residuo_p97_5\": p97_5,\n",
    "        \"quantidade_residuos_extremos\": int(extremos),\n",
    "        \"resumo\": modelo.summary().as_text()\n",
    "    }\n",
    "\n",
    "    return resultados"
   ],
   "id": "978a439fea673366",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_tickers = \"\"\"\n",
    "SELECT *\n",
    "from tickers_ativos\n",
    "\"\"\"\n",
    "df_tickers = pd.read_sql(query_tickers, conn)"
   ],
   "id": "c84a689c1cc87da0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_resultados = df_tickers[\"ticker_name\"].apply(lambda x: regressao_dividendos(x))\n",
    "df_resultados = pd.DataFrame.from_records(df_resultados)"
   ],
   "id": "a10050110250f8ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultados",
   "id": "e614770ae31ec308",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# df_resultados.to_sql(\"beta_dividendo_bruto\", conn, if_exists=\"replace\", index=False)",
   "id": "4bddcb5c3c22cb78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colunas_numericas = df_resultados.select_dtypes(include='number').columns[:24]\n",
    "\n",
    "# Cria o pairplot em resolução alta\n",
    "plot = sns.pairplot(df_resultados[colunas_numericas], corner=True, plot_kws={\"alpha\": 0.5})\n",
    "\n",
    "# Ajusta título e layout\n",
    "plot.fig.suptitle(\"Matriz de Dispersão - Todas contra todas\", fontsize=22)\n",
    "plot.fig.subplots_adjust(top=0.97)  # Deixa espaço pro título\n",
    "\n",
    "# Salva como imagem em alta resolução\n",
    "plot.fig.set_size_inches(40, 40)  # Tamanho grande para qualidade 4K+\n",
    "plot.fig.savefig(\"para_tcc/matriz_dispersao_24x24.png\", dpi=300)\n"
   ],
   "id": "5de689fed1a612c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analise Beta de Dividendo - da base de dados",
   "id": "c7a26f58f9ffd08c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Beta dividendo regressão mercado\n",
   "id": "95c9b476e6e845df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def regressao_dividendos_global():\n",
    "    \"\"\"\n",
    "    Roda a regressão para um ativo específico e retorna os principais indicadores em um dicionário.\n",
    "\n",
    "    Parâmetros:\n",
    "    - ticker_name (str): Código do ativo.\n",
    "    - conn: Conexão com o banco de dados.\n",
    "\n",
    "    Retorna:\n",
    "    - dict com coeficientes, métricas de ajuste, testes estatísticos e detecção de outliers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Consulta os dados do ativo\n",
    "    query = \"\"\"\n",
    "    with cotacoes AS (\n",
    "        SELECT\n",
    "             ticker_name,\n",
    "             Date,\n",
    "             Open,\n",
    "             Close,\n",
    "             Dividends,\n",
    "             LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "        FROM prices\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM cotacoes as c\n",
    "    where\n",
    "        fechamento_ontem IS NOT NULL AND\n",
    "        Dividends != 0 and\n",
    "        ticker_name IN (SELECT ticker_name from tickers_ativos);\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "\n",
    "    # # Filtra apenas os dias com dividendos\n",
    "    # df = df[df[\"Dividends\"] != 0]\n",
    "\n",
    "    # Variável dependente: retorno ajustado\n",
    "    y_ajustado = df[\"Open\"] - df[\"fechamento_ontem\"]\n",
    "\n",
    "    # Variável independente: dividendos + constante\n",
    "    X = df[[\"Dividends\"]]\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Regressão OLS\n",
    "    modelo = sm.OLS(y_ajustado, X).fit()\n",
    "\n",
    "    # Influência e diagnóstico de outliers\n",
    "    influence = modelo.get_influence()\n",
    "    cooks_d = influence.cooks_distance[0]\n",
    "    max_cooks = np.max(cooks_d)\n",
    "    indice_outlier = int(np.argmax(cooks_d))\n",
    "    outlier_flag = max_cooks > 4 / len(df)\n",
    "\n",
    "    # Teste de normalidade dos resíduos\n",
    "    jb_stat, jb_p = jarque_bera(modelo.resid)\n",
    "\n",
    "    # Durbin-Watson para autocorrelação dos resíduos\n",
    "    durbin = sm.stats.stattools.durbin_watson(modelo.resid)\n",
    "\n",
    "    # Percentis dos resíduos\n",
    "    residuos = modelo.resid\n",
    "    p2_5 = np.percentile(residuos, 2.5)\n",
    "    p25 = np.percentile(residuos, 25)\n",
    "    p50 = np.percentile(residuos, 50)\n",
    "    p75 = np.percentile(residuos, 75)\n",
    "    p97_5 = np.percentile(residuos, 97.5)\n",
    "    extremos = np.sum((residuos < p2_5) | (residuos > p97_5))\n",
    "\n",
    "    # Resultados principais\n",
    "    resultados = {\n",
    "        \"ticker_name\": \"Global\",\n",
    "        \"alfa\": modelo.params[\"const\"] if \"const\" in modelo.params else None,\n",
    "        \"beta_dividendo\": modelo.params[\"Dividends\"],\n",
    "        \"erro_alfa\": modelo.bse[\"const\"] if \"const\" in modelo.params else None,\n",
    "        \"erro_beta\": modelo.bse[\"Dividends\"],\n",
    "        \"significancia_alfa\": modelo.pvalues[\"const\"] if \"const\" in modelo.params else None,\n",
    "        \"significancia_beta\": modelo.pvalues[\"Dividends\"],\n",
    "        \"r2\": modelo.rsquared,\n",
    "        \"r2_ajustado\": modelo.rsquared_adj,\n",
    "        \"f_stat\": modelo.fvalue,\n",
    "        \"p_f_stat\": modelo.f_pvalue,\n",
    "        \"durbin_watson\": durbin,\n",
    "        \"jarque_bera\": jb_stat,\n",
    "        \"p_jarque_bera\": jb_p,\n",
    "        \"max_cooks_distance\": max_cooks,\n",
    "        \"indice_outlier\": indice_outlier,\n",
    "        \"possui_outlier_influente\": outlier_flag,\n",
    "        \"residuo_p2_5\": p2_5,\n",
    "        \"residuo_p25\": p25,\n",
    "        \"residuo_p50\": p50,\n",
    "        \"residuo_p75\": p75,\n",
    "        \"residuo_p97_5\": p97_5,\n",
    "        \"quantidade_residuos_extremos\": int(extremos),\n",
    "        \"resumo\": modelo.summary().as_text()\n",
    "    }\n",
    "\n",
    "    return resultados"
   ],
   "id": "2ea7ee15379246e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reg_div_global = regressao_dividendos_global()",
   "id": "a6bd279d49616c58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(reg_div_global['resumo'])",
   "id": "794efa324ecb4a60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exchanges_nasdaq = [\"NasdaqGS\", \"NasdaqCM\", \"NasdaqGM\"]\n",
    "exchanges_nyse = [\"NYSE\",\"NYSE American\"]"
   ],
   "id": "1402825b4674edce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calcular_beta_por_mercado(exchanges_list, nome_grupo):\n",
    "    # Cria placeholders para o número de exchanges\n",
    "    placeholders = ','.join(['?'] * len(exchanges_list))\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH cotacoes AS (\n",
    "        SELECT\n",
    "            ticker_name,\n",
    "            Date,\n",
    "            Open,\n",
    "            Close,\n",
    "            Dividends,\n",
    "            LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "        FROM prices\n",
    "    )\n",
    "    SELECT c.*\n",
    "    FROM cotacoes AS c\n",
    "    INNER JOIN tickers t\n",
    "        ON c.ticker_name = t.ticker_name\n",
    "    WHERE\n",
    "        fechamento_ontem IS NOT NULL AND\n",
    "        Dividends != 0 AND\n",
    "        t.full_exchange_name IN ({placeholders});\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql(query, conn, params=exchanges_list)\n",
    "\n",
    "    if df.empty:\n",
    "        return {\"ticker_name\": nome_grupo, \"erro\": \"Nenhum dado encontrado para esse mercado.\"}\n",
    "\n",
    "    y_ajustado = df[\"Open\"] - df[\"fechamento_ontem\"]\n",
    "    X = sm.add_constant(df[[\"Dividends\"]])\n",
    "\n",
    "    modelo = sm.OLS(y_ajustado, X).fit()\n",
    "\n",
    "    influence = modelo.get_influence()\n",
    "    cooks_d = influence.cooks_distance[0]\n",
    "    max_cooks = np.max(cooks_d)\n",
    "    indice_outlier = int(np.argmax(cooks_d))\n",
    "    outlier_flag = max_cooks > 4 / len(df)\n",
    "\n",
    "    jb_stat, jb_p = jarque_bera(modelo.resid)\n",
    "    durbin = sm.stats.stattools.durbin_watson(modelo.resid)\n",
    "\n",
    "    residuos = modelo.resid\n",
    "    p2_5 = np.percentile(residuos, 2.5)\n",
    "    p25 = np.percentile(residuos, 25)\n",
    "    p50 = np.percentile(residuos, 50)\n",
    "    p75 = np.percentile(residuos, 75)\n",
    "    p97_5 = np.percentile(residuos, 97.5)\n",
    "    extremos = np.sum((residuos < p2_5) | (residuos > p97_5))\n",
    "\n",
    "    resultados = {\n",
    "        \"ticker_name\": nome_grupo,\n",
    "        \"alfa\": modelo.params.get(\"const\"),\n",
    "        \"beta_dividendo\": modelo.params[\"Dividends\"],\n",
    "        \"erro_alfa\": modelo.bse.get(\"const\"),\n",
    "        \"erro_beta\": modelo.bse[\"Dividends\"],\n",
    "        \"significancia_alfa\": modelo.pvalues.get(\"const\"),\n",
    "        \"significancia_beta\": modelo.pvalues[\"Dividends\"],\n",
    "        \"r2\": modelo.rsquared,\n",
    "        \"r2_ajustado\": modelo.rsquared_adj,\n",
    "        \"f_stat\": modelo.fvalue,\n",
    "        \"p_f_stat\": modelo.f_pvalue,\n",
    "        \"durbin_watson\": durbin,\n",
    "        \"jarque_bera\": jb_stat,\n",
    "        \"p_jarque_bera\": jb_p,\n",
    "        \"max_cooks_distance\": max_cooks,\n",
    "        \"indice_outlier\": indice_outlier,\n",
    "        \"possui_outlier_influente\": outlier_flag,\n",
    "        \"residuo_p2_5\": p2_5,\n",
    "        \"residuo_p25\": p25,\n",
    "        \"residuo_p50\": p50,\n",
    "        \"residuo_p75\": p75,\n",
    "        \"residuo_p97_5\": p97_5,\n",
    "        \"quantidade_residuos_extremos\": int(extremos),\n",
    "        \"resumo\": modelo.summary().as_text()\n",
    "    }\n",
    "\n",
    "    return resultados\n"
   ],
   "id": "7632531480c874a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "beta_nasdaq = calcular_beta_por_mercado(exchanges_nasdaq, \"NASDAQ\")\n",
    "beta_nyse = calcular_beta_por_mercado(exchanges_nyse, \"NYSE\")"
   ],
   "id": "b2fac2bd315f7414",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(beta_nyse['resumo'])",
   "id": "2cf84ad028fcbd5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(beta_nasdaq['resumo'])",
   "id": "9c4789262fda5029",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "beta_nasdaqGS = calcular_beta_por_mercado([\"NasdaqGS\"], \"NASDAQ_GS\")\n",
    "beta_nasdaqCM = calcular_beta_por_mercado([\"NasdaqCM\"], \"NASDAQ_CM\")\n",
    "beta_nasdaqGM = calcular_beta_por_mercado([\"NasdaqGM\"], \"NASDAQ_GM\")"
   ],
   "id": "c9e3f8c1227b2daf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(beta_nasdaqGS['resumo'])",
   "id": "e00c4c1d15219ee4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(beta_nasdaqGM['resumo'])",
   "id": "ba47e2dd66186e6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(beta_nasdaqCM['resumo'])",
   "id": "18f017f58a31a15c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "beta_nyse_only = calcular_beta_por_mercado([\"NYSE\"], \"NYSE\")\n",
    "beta_nyseAmerican = calcular_beta_por_mercado([\"NYSE American\"], \"NYSE American\")"
   ],
   "id": "3c0a7d7a191967ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(beta_nyse_only['resumo'])",
   "id": "c7a21f5c9fec67b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(beta_nyseAmerican['resumo'])",
   "id": "99faf69907a243e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analises Globais",
   "id": "e239176d8653f1ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultados = pd.read_sql(\"SELECT * FROM beta_dividendo_bruto\", conn)",
   "id": "ebbe864bcca7f797",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tratar_binario(val):\n",
    "    if isinstance(val, bytes):\n",
    "        try:\n",
    "            unpacked = struct.unpack('d', val)[0]\n",
    "            if unpacked == float('inf'):\n",
    "                return float('inf')\n",
    "            else:\n",
    "                return unpacked\n",
    "        except:\n",
    "            return np.nan\n",
    "    return val  # já é float"
   ],
   "id": "f56251366a211711",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_resultados[\"p_f_stat\"] = df_resultados[\"p_f_stat\"].apply(tratar_binario)\n",
    "df_resultados[\"p_f_stat\"] = df_resultados[\"p_f_stat\"].astype(\"float64\")"
   ],
   "id": "c1c183b1817159dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analise Alfa",
   "id": "5bd96e720999e096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "analise_alfa = df_resultados[['ticker_name','alfa','erro_alfa','significancia_alfa']]",
   "id": "9c922bd9e01b5ad6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Parâmetros\n",
    "dados = analise_alfa['alfa']\n",
    "\n",
    "media = dados.mean()\n",
    "desvio = dados.std()\n",
    "\n",
    "min = int(media + -3.5 *desvio)\n",
    "max = int(media + 3.5 *desvio)\n",
    "bins = np.arange(min,max, 0.25)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(dados, bins=bins, edgecolor='black', alpha=0.7, label='Frequência')\n",
    "\n",
    "# Linhas de referência\n",
    "plt.axvline(media, color='red', linestyle='--', label=f'Média: {media:.4f}')\n",
    "plt.axvline(media, color='black', linestyle='none', linewidth=0, label=f'σ: {desvio:.4f}')\n",
    "for i, color, label in zip([1, 2, 3], ['green', 'blue', 'purple'], [r'±1σ', r'±2σ', r'±3σ']):\n",
    "    plt.axvline(media + i * desvio, color=color, linestyle='--', label=f'+{label}')\n",
    "    plt.axvline(media - i * desvio, color=color, linestyle='--')\n",
    "\n",
    "# Título e legenda\n",
    "plt.title('Distribuição em Barras do Alfa')\n",
    "plt.xlabel('Alfa')\n",
    "plt.ylabel('Frequência')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "eebaf443c2936c19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dados = analise_alfa['alfa']\n",
    "significancia = analise_alfa['significancia_alfa']\n",
    "\n",
    "# Define os limites de significância\n",
    "limiares = [0.05, 0.10, 0.15,1]\n",
    "index = 0\n",
    "tabela_resultado = []\n",
    "\n",
    "for limite in limiares:\n",
    "    filtro = significancia <= limite\n",
    "    if index > 0:\n",
    "        filtro = (significancia <= limite) & (significancia > limiares[index-1])\n",
    "    subset = dados[filtro]\n",
    "    stats = subset.describe()\n",
    "\n",
    "    tabela_resultado.append({\n",
    "        'Limite Significância': f'{int(limiares[index-1]*100) if index > 0 else 0}% <= {int(limite*100)}%',\n",
    "        'Contagem': len(subset),\n",
    "        'Média': stats['mean'],\n",
    "        'Mediana': stats['50%'],\n",
    "        'Desvio Padrão': stats['std'],\n",
    "        'Mínimo': stats['min'],\n",
    "        'Máximo': stats['max']\n",
    "    })\n",
    "    index += 1\n",
    "\n",
    "pd.DataFrame(tabela_resultado)"
   ],
   "id": "63595f72f25355c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df_resultados[['ticker_name','alfa','erro_alfa','significancia_alfa']].copy()\n",
    "\n",
    "# Distância padronizada de alfa ao zero\n",
    "df['distancia_padronizada'] = abs(df['alfa'] / df['erro_alfa'])\n",
    "\n",
    "# Estatísticas descritivas\n",
    "resumo_distancia = df['distancia_padronizada'].describe(percentiles=[.25, .5, .75, .95, .99])"
   ],
   "id": "7c0ce57e8179e4f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "resumo_distancia",
   "id": "559ceb466084f075",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analise R2",
   "id": "555a2fd1741406b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultados",
   "id": "f146ab6d978991f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "analise_r2 = df_resultados[['ticker_name', 'r2']]\n",
    "# Parâmetros\n",
    "dados = analise_r2['r2']\n",
    "\n",
    "media = dados.mean()\n",
    "desvio = dados.std()\n",
    "\n",
    "min = -0.05\n",
    "max = 1\n",
    "bins = np.arange(min, max, 0.005)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(dados, bins=bins, edgecolor='black', alpha=0.7, label='Frequência')\n",
    "\n",
    "# Linhas de referência\n",
    "plt.axvline(media, color='red', linestyle='--', label=f'Média: {media:.4f}')\n",
    "plt.axvline(media, color='black', linestyle='none', linewidth=0, label=f'σ: {desvio:.4f}')\n",
    "\n",
    "# Título e legenda\n",
    "plt.title('Distribuição em Barras do R2')\n",
    "plt.xlabel('R2')\n",
    "plt.ylabel('Frequência')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.xlim(min,max)\n",
    "plt.show()"
   ],
   "id": "22fae467be374929",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "analise_r2",
   "id": "9f7f16f408487165",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dados = analise_r2['r2']  # Agora analisando o R²\n",
    "\n",
    "# Define as faixas de significância\n",
    "limiares = np.arange(0, 1.01, 0.05)\n",
    "tabela_resultado = []\n",
    "\n",
    "for i, limite in enumerate(limiares):\n",
    "    if i == 0:\n",
    "        filtro = dados <= limite\n",
    "    else:\n",
    "        filtro = (dados > limiares[i - 1]) & (dados <= limite)\n",
    "\n",
    "    subset = dados[filtro]\n",
    "    stats = subset.describe()\n",
    "\n",
    "    tabela_resultado.append({\n",
    "        'Faixa': f'{f\"{int(limiares[i - 1]*100)}%\" if i > 0 else \"Min\"} <= {int(limite*100)}%',\n",
    "        'Contagem': len(subset),\n",
    "        'Média': round(stats['mean'],4) if not subset.empty else np.nan,\n",
    "        'Mediana': round(stats['50%'],4) if not subset.empty else np.nan,\n",
    "        'Desvio Padrão': round(stats['std'],4) if not subset.empty else np.nan,\n",
    "        'Mínimo': round(stats['min'],4) if not subset.empty else np.nan,\n",
    "        'Máximo': round(stats['max'],4) if not subset.empty else np.nan\n",
    "    })\n",
    "\n",
    "df_resultado = pd.DataFrame(tabela_resultado)"
   ],
   "id": "1da78e1fd483c548",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultado",
   "id": "a63df25fe81ebed8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultados.describe().T",
   "id": "50b687203ebdf6ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Parâmetros\n",
    "dados = df_resultados['beta_dividendo']\n",
    "bins = np.arange(-50, 51, 1)\n",
    "media = dados.mean()\n",
    "desvio = dados.std()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(dados, bins=bins, edgecolor='black', alpha=0.7, label='Frequência')\n",
    "\n",
    "# Linhas de referência\n",
    "plt.axvline(media, color='red', linestyle='--', label=f'Média: {media:.4f}')\n",
    "plt.axvline(media, color='black', linestyle='none', linewidth=0, label=f'σ: {desvio:.4f}')\n",
    "for i, color, label in zip([1, 2, 3], ['green', 'blue', 'purple'], [r'±1σ', r'±2σ', r'±3σ']):\n",
    "    plt.axvline(media + i * desvio, color=color, linestyle='--', label=f'+{label}')\n",
    "    plt.axvline(media - i * desvio, color=color, linestyle='--')\n",
    "\n",
    "# Título e legenda\n",
    "plt.title('Distribuição em Barras do Beta de Dividendo')\n",
    "plt.xlabel('Beta de Dividendo')\n",
    "plt.ylabel('Frequência')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "a3a597c9ca032836",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar o gráfico de densidade do Beta de Dividendo\n",
    "df_resultados_significantes = df_resultados.loc[df_resultados[\"significancia_beta\"] < 0.05]\n",
    "dados = df_resultados_significantes[\"beta_dividendo\"]\n",
    "bins = np.arange(-50, 51, 1)\n",
    "media = dados.mean()\n",
    "desvio = dados.std()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(dados, bins=bins, edgecolor='black', alpha=0.7, label='Frequência')\n",
    "\n",
    "# Linhas de referência\n",
    "plt.axvline(media, color='red', linestyle='--', label=f'Média: {media:.4f}')\n",
    "plt.axvline(media, color='black', linestyle='none', linewidth=0, label=f'σ: {desvio:.4f}')\n",
    "for i, color, label in zip([1, 2, 3], ['green', 'blue', 'purple'], [r'±1σ', r'±2σ', r'±3σ']):\n",
    "    plt.axvline(media + i * desvio, color=color, linestyle='--', label=f'+{label}')\n",
    "    plt.axvline(media - i * desvio, color=color, linestyle='--')\n",
    "\n",
    "# Título e legenda\n",
    "plt.title('Distribuição em Barras do Beta de Dividendo Significantes')\n",
    "plt.xlabel('Beta de Dividendo')\n",
    "plt.ylabel('Frequência')\n",
    "plt.xlim(-25,25)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6eea2941cf8944bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Recalcular as estatísticas para incluir média e desvio-padrão\n",
    "df_resultados[\"r2_bin\"] = (df_resultados[\"r2\"] // 0.03) * 0.03\n",
    "\n",
    "# Agrupar por faixas de R² e calcular os valores\n",
    "grouped = df_resultados.groupby(\"r2_bin\")[\"beta_dividendo\"].agg([\"min\", \"max\", \"mean\", \"std\"])\n",
    "\n",
    "# Definir limites de 3 desvios-padrão para cada lado\n",
    "grouped[\"lower_bound\"] = grouped[\"mean\"] - 3 * grouped[\"std\"]\n",
    "grouped[\"upper_bound\"] = grouped[\"mean\"] + 3 * grouped[\"std\"]\n",
    "\n",
    "# Criar o gráfico\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plotar as barras flutuantes (intervalo total de beta)\n",
    "for i, (r2_bin, row) in enumerate(grouped.iterrows()):\n",
    "    ax.plot([r2_bin, r2_bin], [row[\"min\"], row[\"max\"]], color=\"b\", linewidth=4, alpha=0.5, label=\"Máx/Mín\" if i == 0 else \"\")\n",
    "\n",
    "# Plotar os intervalos de 3 desvios-padrão ao redor da média\n",
    "for i, (r2_bin, row) in enumerate(grouped.iterrows()):\n",
    "    ax.plot([r2_bin, r2_bin], [row[\"lower_bound\"], row[\"upper_bound\"]], color=\"orange\", linewidth=4, alpha=0.9, label=\"Média ± 3σ\" if i == 0 else \"\")\n",
    "\n",
    "# Plotar a média de beta como pontos\n",
    "ax.scatter(grouped.index, grouped[\"mean\"], color=\"black\", marker=\"o\", s=50, label=\"Média\")\n",
    "\n",
    "# Adicionar a linha horizontal em -1\n",
    "ax.axhline(y=-1, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Linha em -1\")\n",
    "\n",
    "# Configurações do gráfico\n",
    "ax.set_xlabel(\"Faixas de R²\", fontsize=12)\n",
    "ax.set_ylabel(\"Coeficiente Beta\", fontsize=12)\n",
    "ax.set_title(\"Distribuição do Beta por Faixa de R² (com Intervalo de Confiança)\", fontsize=14)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "ax.set_xticks(np.arange(0, 1.05, 0.05))\n",
    "ax.set_xlim(-0.01, 1.01)\n",
    "ax.set_ylim(-20, 20)\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.show()"
   ],
   "id": "5e45dd9eca69703a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analise Beta",
   "id": "3fbffc84f3338b9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultados",
   "id": "e55812b1397904b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultados['beta_dividendo']",
   "id": "21cc73eed1bd0635",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dados = df_resultados['beta_dividendo']\n",
    "\n",
    "# Define os quintis (com labels numéricos de 0 a 4)\n",
    "# Número de grupos (pode trocar aqui por 4, 5, 10, etc.)\n",
    "k = 5\n",
    "\n",
    "# Segmenta os dados com qcut\n",
    "quintis = pd.qcut(dados, q=k, labels=False, duplicates='drop')\n",
    "\n",
    "# Cria paleta de cores em gradiente (colormap 'coolwarm' ou qualquer outro)\n",
    "cmap = matplotlib.colormaps['coolwarm']\n",
    "cores = [cmap(i / (k - 1)) for i in range(k)]\n",
    "\n",
    "# DataFrame com valores e quintis\n",
    "df_quintil = pd.DataFrame({'valor': dados, 'quintil': quintis})\n",
    "\n",
    "# Parâmetros do gráfico\n",
    "min_x = -20\n",
    "max_x = 20\n",
    "bins = np.arange(min_x, max_x, 0.2)\n",
    "\n",
    "# Criação do gráfico\n",
    "plt.figure(figsize=(12, 7))\n",
    "for q in range(k):\n",
    "    subset = df_quintil[df_quintil['quintil'] == q]['valor']\n",
    "    q_min = subset.min()\n",
    "    q_max = subset.max()\n",
    "    label = f'Quintil {q+1}: [{q_min:.3f}, {q_max:.3f}]'\n",
    "    plt.hist(subset, bins=bins, alpha=0.7, label=label, color=cores[q], edgecolor='black')\n",
    "\n",
    "# Linhas de média e desvio\n",
    "media = dados.mean()\n",
    "desvio = dados.std()\n",
    "plt.axvline(media, color='red', linestyle='--', label=f'Média: {media:.4f}')\n",
    "plt.axvline(media, color='black', linestyle='none', linewidth=0, label=f'σ: {desvio:.4f}')\n",
    "\n",
    "# Título e eixos com LaTeX\n",
    "plt.title(r'Distribuição de $\\beta_{div}$ segmentada por quintis')\n",
    "plt.xlabel(r'$\\beta_{div}$')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Estética final\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.xlim(min_x, max_x)\n",
    "plt.show()\n"
   ],
   "id": "1c97bdb4b96d02e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "p5 = dados.quantile(0.05)\n",
    "p95 = dados.quantile(0.95)\n",
    "\n",
    "df_limpa = df_resultados[(df_resultados['beta_dividendo'] >= p5) & (df_resultados['beta_dividendo'] <= p95)]\n"
   ],
   "id": "e36932c0da976b17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dados = df_limpa['beta_dividendo']\n",
    "\n",
    "# Define os quintis (com labels numéricos de 0 a 4)\n",
    "# Número de grupos (pode trocar aqui por 4, 5, 10, etc.)\n",
    "k = 5\n",
    "\n",
    "# Segmenta os dados com qcut\n",
    "quintis = pd.qcut(dados, q=k, labels=False, duplicates='drop')\n",
    "\n",
    "# Cria paleta de cores em gradiente (colormap 'coolwarm' ou qualquer outro)\n",
    "cmap = matplotlib.colormaps['coolwarm']\n",
    "cores = [cmap(i / (k - 1)) for i in range(k)]\n",
    "\n",
    "# DataFrame com valores e quintis\n",
    "df_quintil = pd.DataFrame({'valor': dados, 'quintil': quintis})\n",
    "\n",
    "# Parâmetros do gráfico\n",
    "min_x = p5 - 0.20\n",
    "max_x = p95 + 0.20\n",
    "bins = np.arange(min_x, max_x, 0.2)\n",
    "\n",
    "# Criação do gráfico\n",
    "plt.figure(figsize=(12, 7))\n",
    "for q in range(k):\n",
    "    subset = df_quintil[df_quintil['quintil'] == q]['valor']\n",
    "    q_min = subset.min()\n",
    "    q_max = subset.max()\n",
    "    label = f'Quintil {q+1}: [{q_min:.3f}, {q_max:.3f}]'\n",
    "    plt.hist(subset, bins=bins, alpha=0.7, label=label, color=cores[q], edgecolor='black')\n",
    "\n",
    "# Linhas de média e desvio\n",
    "media = dados.mean()\n",
    "desvio = dados.std()\n",
    "plt.axvline(media, color='red', linestyle='--', label=f'Média: {media:.4f}')\n",
    "plt.axvline(media, color='black', linestyle='none', linewidth=0, label=f'σ: {desvio:.4f}')\n",
    "\n",
    "# Título e eixos com LaTeX\n",
    "plt.title(r'Distribuição de $\\beta_{div}$ segmentada por quintis')\n",
    "plt.xlabel(r'$\\beta_{div}$')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Estética final\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.xlim(min_x, max_x)\n",
    "plt.show()\n"
   ],
   "id": "d2c8e0d721ceb523",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## O que explica o β_div?",
   "id": "62d4ca38ffd099b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_final = \"\"\"\n",
    "WITH dividendos_filtrados AS (\n",
    "    SELECT\n",
    "        ca.ticker_name,\n",
    "        t.sector_key,\n",
    "        t.full_exchange_name,\n",
    "        ca.Date,\n",
    "        ca.Dividends,\n",
    "        ca.fechamento_ontem\n",
    "    FROM cotacoes_ativos ca\n",
    "    LEFT JOIN tickers t ON t.ticker_name = ca.ticker_name\n",
    "    WHERE ca.Dividends != 0\n",
    "),\n",
    "dias_entre_dividendos AS (\n",
    "    SELECT\n",
    "        ticker_name,\n",
    "        Date,\n",
    "        Dividends,\n",
    "        julianday(Date) - julianday(\n",
    "            LAG(Date) OVER (PARTITION BY ticker_name ORDER BY Date)\n",
    "        ) AS dias_entre\n",
    "    FROM dividendos_filtrados\n",
    "),\n",
    "periodo_medio AS (\n",
    "    SELECT\n",
    "        ticker_name,\n",
    "        AVG(dias_entre) AS avg_dias_entre_div\n",
    "    FROM dias_entre_dividendos\n",
    "    WHERE dias_entre IS NOT NULL\n",
    "    GROUP BY ticker_name\n",
    "),\n",
    "crescimento_div AS (\n",
    "    SELECT\n",
    "        df.*,\n",
    "        LAG(Dividends) OVER (PARTITION BY ticker_name ORDER BY Date) AS prev_div\n",
    "    FROM dividendos_filtrados df\n",
    "),\n",
    "crescimento_agrupado AS (\n",
    "    SELECT\n",
    "        ticker_name,\n",
    "        sector_key,\n",
    "        full_exchange_name,\n",
    "        AVG(Dividends / fechamento_ontem) AS proxy_div_yield,\n",
    "        AVG(\n",
    "            CASE\n",
    "                WHEN prev_div IS NOT NULL AND prev_div > 0\n",
    "                THEN (Dividends - prev_div) / prev_div\n",
    "                ELSE NULL\n",
    "            END\n",
    "        ) AS avg_div_growth\n",
    "    FROM crescimento_div\n",
    "    GROUP BY ticker_name, sector_key, full_exchange_name\n",
    ")\n",
    "SELECT\n",
    "    bdb.beta_dividendo,\n",
    "    c.*,\n",
    "    p.avg_dias_entre_div / 30.44 AS 'avg_tempo_entre_divs_meses'\n",
    "FROM crescimento_agrupado c\n",
    "LEFT JOIN periodo_medio p USING (ticker_name)\n",
    "LEFT JOIN beta_dividendo_bruto bdb\n",
    "    on bdb.ticker_name = c.ticker_name;\n",
    "\"\"\"\n",
    "\n",
    "df_explicando_beta = pd.read_sql(query_final, conn)"
   ],
   "id": "9f845b49f9971178",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_filtrada = df_explicando_beta[\n",
    "    df_explicando_beta['ticker_name'].isin(df_limpa['ticker_name'])\n",
    "]"
   ],
   "id": "4801d40582d59b10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# df_filtrada.to_csv(\"bot, explica essa para mim.csv\", index=False)",
   "id": "5a22ed87afaa4fb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_base = df_filtrada[[\n",
    "    \"proxy_div_yield\",\n",
    "    \"avg_div_growth\",\n",
    "    \"avg_tempo_entre_divs_meses\"\n",
    "]]\n",
    "\n",
    "# 2. Cria as dummies\n",
    "d_sector  = pd.get_dummies(df_filtrada[\"sector_key\"],\n",
    "                           prefix=\"sector\", drop_first=True,dtype=int)  # baseline implícito\n",
    "d_exchange = pd.get_dummies(df_filtrada[\"full_exchange_name\"],\n",
    "                            prefix=\"exch\", drop_first=True,dtype=int)\n",
    "\n",
    "# 3. Garante ordem: primeiro X_base, depois dummies\n",
    "X = pd.concat([X_base, d_sector, d_exchange], axis=1)\n",
    "\n",
    "# 4. Adiciona o intercepto (α)\n",
    "X = sm.add_constant(X, has_constant=\"add\")\n",
    "\n",
    "# 5. Variável dependente\n",
    "y = df_filtrada[\"beta_dividendo\"]\n",
    "\n",
    "# 6. Ajusta o modelo OLS com erros robustos (HC3)\n",
    "model = sm.OLS(y, X).fit(cov_type=\"HC3\")"
   ],
   "id": "379d65573b39a181",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(model.summary())",
   "id": "8e0430afc55421d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## OUTLIERS",
   "id": "ec193bb1aa26d180"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Obtendo Outliers",
   "id": "542c49e3c99af713"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_betas = \"\"\"\n",
    "SELECT bdb.beta_dividendo\n",
    "FROM beta_dividendo_bruto bdb\n",
    "\"\"\"\n",
    "df_betas = pd.read_sql(query_betas, conn)\n",
    "\n",
    "Q1 = df_betas['beta_dividendo'].quantile(0.25)\n",
    "Q3 = df_betas['beta_dividendo'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "limite_inferior = Q1 - 1.5 * IQR\n",
    "limite_superior = Q3 + 1.5 * IQR\n"
   ],
   "id": "ee66989deb893c68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_outliers = f\"\"\"\n",
    "SELECT *\n",
    "FROM beta_dividendo_bruto bdb\n",
    "WHERE\n",
    "    bdb.beta_dividendo < {limite_inferior}\n",
    "    OR bdb.beta_dividendo > {limite_superior};\n",
    "\"\"\"\n",
    "\n",
    "df_outliers = pd.read_sql(query_outliers, conn)"
   ],
   "id": "6484ac768a898448",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Outliers = Volume?",
   "id": "3c83471ddde760ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "conn.create_aggregate(\"stdev\", 1, StdevFunc)\n",
    "query_dados_com_beta = \"\"\"\n",
    "SELECT\n",
    "    bdb.*,\n",
    "    t.beta as 'Beta CAPM',\n",
    "    t.market_cap,\n",
    "    t.dividend_rate,\n",
    "    t.dividend_yield,\n",
    "    t.payout_ratio,\n",
    "    t.price_to_book,\n",
    "    t.price_to_earnings,\n",
    "    t.free_cashflow,\n",
    "    avg(p.Volume) as 'Volume Medio',\n",
    "    stdev(p.Volume) as 'Desvio Volume'\n",
    "FROM tickers t\n",
    "INNER JOIN beta_dividendo_bruto bdb\n",
    "    ON bdb.ticker_name = t.ticker_name\n",
    "INNER JOIN prices p on bdb.ticker_name = p.ticker_name\n",
    "group by t.ticker_name;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query_dados_com_beta, conn)\n",
    "\n",
    "df = df[(df[\"beta_dividendo\"] > -10) & (df[\"beta_dividendo\"] < 10)]\n",
    "df['log_volume_medio'] = np.log10(df['Volume Medio'])\n",
    "\n",
    "# 1. Garantir que as colunas necessárias existem\n",
    "df['log_volume_medio'] = np.log10(df['Volume Medio'] + 1)\n",
    "df['faixa_volume'] = pd.cut(df['log_volume_medio'], bins=6)\n",
    "\n",
    "# 2. Função customizada para desenhar no FacetGrid\n",
    "def plot_beta_com_linhas(data, color=None, **kwargs):\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Histograma com KDE\n",
    "    sns.histplot(data['beta_dividendo'], bins=30, kde=True, ax=ax, color=color)\n",
    "\n",
    "    # Linhas verticais\n",
    "    media = data['beta_dividendo'].mean()\n",
    "    std = data['beta_dividendo'].std()\n",
    "\n",
    "    ax.axvline(-1, color='white', linestyle='--', label='Linha -1')\n",
    "    ax.axvline(media, color='yellow', linestyle='-', label='Média')\n",
    "\n",
    "    # Desvios padrão\n",
    "    for i in range(1, 4):\n",
    "        ax.axvline(media + i*std, color='red', linestyle='--', alpha=0.7)\n",
    "        ax.axvline(media - i*std, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 3. Criar FacetGrid e aplicar a função\n",
    "g = sns.FacetGrid(df, col='faixa_volume', col_wrap=3, height=4, sharey=True)\n",
    "g.map_dataframe(plot_beta_com_linhas)\n",
    "\n",
    "# 4. Ajustar layout\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle(\"Distribuição de beta_dividendo com média, desvios e linha em -1\")\n",
    "plt.show()\n"
   ],
   "id": "93ef07261f689af4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.groupby('faixa_volume', observed=True)['beta_dividendo'].agg(['mean', 'std', 'count'])",
   "id": "e04df6f932beb9c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df['log_desvio_volume'] = np.log10(df['Desvio Volume'])\n",
    "df['faixa_log_desvio_volume'] = pd.cut(df['log_desvio_volume'], bins=6)\n",
    "\n",
    "g = sns.FacetGrid(df, col='faixa_log_desvio_volume', col_wrap=3, height=4, sharey=True)\n",
    "g.map_dataframe(plot_beta_com_linhas)\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle(\"Distribuição de beta_dividendo por log(desvio do volume médio)\")\n",
    "plt.show()"
   ],
   "id": "6b0628f4c0ccfc52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.groupby('faixa_log_desvio_volume', observed=True)['beta_dividendo'].agg(['count', 'mean', 'std'])",
   "id": "b826b0de54df6b88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tickers_outliers = tuple(df_outliers['ticker_name'].unique())\n",
    "df['é_outlier'] = df['ticker_name'].isin(tickers_outliers)"
   ],
   "id": "d6a3a596ac67a8ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define o número de intervalos desejados\n",
    "num_bins = 20\n",
    "min_val = df['log_volume_medio'].min()\n",
    "max_val = df['log_volume_medio'].max()\n",
    "\n",
    "# Cria os intervalos (bins)\n",
    "bins = np.linspace(min_val, max_val, num_bins + 1)\n",
    "\n",
    "# Agrupa os dados em intervalos\n",
    "df['bin'] = pd.cut(df['log_volume_medio'], bins=bins)\n",
    "\n",
    "# Agrupa os dados por intervalo e pelo flag de outlier, contando os registros\n",
    "group_counts = df.groupby(['bin', 'é_outlier'], observed=True).size().unstack(fill_value=0)\n",
    "\n",
    "# Calcula a coluna Total (soma de outliers e não outliers)\n",
    "group_counts['Total'] = group_counts[False] + group_counts[True]\n",
    "\n",
    "# Reordena as colunas para que Total venha antes de Não Outlier\n",
    "group_counts = group_counts[['Total', False, True]]\n",
    "\n",
    "# Define posições no eixo X para cada intervalo e a largura de cada barra\n",
    "x = np.arange(len(group_counts.index))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plota a barra Total (antes das demais)\n",
    "plt.bar(x - width, group_counts['Total'], width, label='Total', color='gray')\n",
    "# Plota a barra Não Outlier (False)\n",
    "plt.bar(x, group_counts[False], width, label='Não Outlier', color='blue')\n",
    "# Plota a barra Outlier (True)\n",
    "plt.bar(x + width, group_counts[True], width, label='Outlier', color='red')\n",
    "\n",
    "# Formata os labels do eixo X com os intervalos\n",
    "interval_labels = [f'{interval.left:.2f} a {interval.right:.2f}' for interval in group_counts.index]\n",
    "plt.xticks(x, interval_labels, rotation=45)\n",
    "\n",
    "# Eixos e título\n",
    "plt.xlabel('Intervalos do Log do Volume Médio')\n",
    "plt.ylabel('Contagem de Valores')\n",
    "plt.title('Contagem por Intervalos do Log(Volume Médio)\\n(Total, Não Outliers e Outliers)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a7e8c7a71ba66362",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(df)",
   "id": "7ceb9230d475acb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hipotese Setores = Outliers",
   "id": "23de3dab8e676f7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tickers_outliers = tuple(df_outliers['ticker_name'].unique())\n",
    "\n",
    "query_setores_outliers = \"\"\"\n",
    "SELECT t.sector, COUNT(t.sector)\n",
    "FROM tickers t\n",
    "WHERE t.ticker_name IN ({seq})\n",
    "GROUP BY t.sector\n",
    "\"\"\".format(seq=','.join(['?'] * len(tickers_outliers)))\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query_setores_outliers, tickers_outliers)\n",
    "resultados = cursor.fetchall()\n",
    "cursor.close()\n",
    "\n",
    "setores_outliers = pd.DataFrame(resultados)"
   ],
   "id": "84f51864d46a3fa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_setores_totais = \"\"\"\n",
    "SELECT t.sector, COUNT(t.sector)\n",
    "FROM tickers t\n",
    "GROUP BY t.sector\n",
    "\"\"\"\n",
    "setores_totais = pd.read_sql(query_setores_totais, conn)\n"
   ],
   "id": "a8e8308b9b56200d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "setores_outliers.columns = ['Setores', \"Contagem Outlier\"]\n",
    "setores_totais.columns = ['Setores', \"Contagem\"]"
   ],
   "id": "ab194c9d37e7af61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_setores = setores_totais.merge(setores_outliers, on='Setores', how='left')",
   "id": "53abb3a21428d4f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_setores['Contagem Outlier'] = df_setores['Contagem Outlier'].fillna(0).astype(int)\n",
    "df_setores['% Outlier'] = (df_setores['Contagem Outlier'] / df_setores['Contagem']) * 100"
   ],
   "id": "f9beeb62dece2050",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_setores",
   "id": "8282c0ca8d6a95ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Testes Outliers Individuais\n",
    "\n",
    "- Valida, mas como fazer em larga escala?"
   ],
   "id": "eda1ddfee22679ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ticker_name = \"AYI\"\n",
    "\n",
    "# Query original que você já tem\n",
    "query_cotacoes_por_ativo = \"\"\"\n",
    "with cotacoes AS (\n",
    "    SELECT ticker_name,\n",
    "         Date,\n",
    "         Open,\n",
    "         Close,\n",
    "         Dividends,\n",
    "         LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "    FROM prices\n",
    ")\n",
    "SELECT *\n",
    "FROM cotacoes as c\n",
    "where\n",
    "    fechamento_ontem IS NOT NULL AND\n",
    "    ticker_name == ?;\n",
    "\"\"\"\n",
    "\n",
    "# Lendo dados\n",
    "df = pd.read_sql(query_cotacoes_por_ativo, conn, params=[ticker_name])\n",
    "\n",
    "# Filtrando apenas eventos com dividendos\n",
    "df = df[df[\"Dividends\"] != 0].copy()\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'], utc=True)\n",
    "df['Date'] = df['Date'].dt.tz_convert(None)\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.normalize()\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.tz_localize(None)\n",
    "\n",
    "# Lista de datas a remover (sem timezone)\n",
    "# Exemplo     '2024-11-20',\n",
    "datas_remover = [\n",
    "\n",
    "]\n",
    "\n",
    "# Converte para datetime sem timezone\n",
    "datas_remover = pd.to_datetime(datas_remover)\n",
    "\n",
    "# Filtra\n",
    "df = df[~df['Date'].isin(datas_remover)]\n",
    "\n",
    "# Calculando variação real\n",
    "df[\"ajuste\"] = df[\"Open\"] - df[\"fechamento_ontem\"]\n",
    "\n",
    "# Rodando regressão\n",
    "X = sm.add_constant(df[[\"Dividends\"]])\n",
    "y = df[\"ajuste\"]\n",
    "\n",
    "modelo = sm.OLS(y, X).fit()\n",
    "\n",
    "# Mostra os parâmetros\n",
    "print(\"\\n📊 Regressão para:\", ticker_name)\n",
    "print(\"Beta:\", modelo.params[\"Dividends\"])\n",
    "print(\"Intercepto:\", modelo.params[\"const\"])\n",
    "print(\"R²:\", modelo.rsquared)\n",
    "print(\"P-valor:\", modelo.pvalues[\"Dividends\"])"
   ],
   "id": "c23f61d3a13f8af2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inclui resíduos para investigar pontos anômalos\n",
    "df[\"residuo\"] = modelo.resid\n",
    "df[\"ajuste_previsto\"] = modelo.predict(X)\n",
    "\n",
    "# Mostra os eventos ordenados pelos resíduos mais extremos\n",
    "print(\"\\n🔎 Top eventos que mais puxaram a regressão (maior desvio):\")\n",
    "df.sort_values(\"residuo\", key=abs, ascending=False).head(20)[\n",
    "    [\"Date\", \"Dividends\", \"fechamento_ontem\", \"Open\", \"ajuste\", \"ajuste_previsto\", \"residuo\"]\n",
    "]"
   ],
   "id": "f493bacba4e70206",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Hipotese Yield\n",
    "\n",
    "Trago pela AAPL pelo baixa distribuição de dividendo perto dos preços, 0,23 com o preço sendo 165, potencial"
   ],
   "id": "bf3edcda94c50303"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_yield = \"\"\"\n",
    "WITH cotacoes AS (\n",
    "    SELECT\n",
    "        ticker_name,\n",
    "        Date,\n",
    "        Open,\n",
    "        Close,\n",
    "        Dividends,\n",
    "        LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "    FROM prices\n",
    ")\n",
    "SELECT\n",
    "    ticker_name,\n",
    "    AVG(Dividends / fechamento_ontem) AS dividend_yield\n",
    "FROM cotacoes\n",
    "WHERE\n",
    "    fechamento_ontem IS NOT NULL\n",
    "    AND Dividends != 0\n",
    "GROUP BY ticker_name;\n",
    "\"\"\"\n",
    "\n",
    "df_yield_medio = pd.read_sql(query_yield, conn)"
   ],
   "id": "d90dbd33d9a538e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lista dos tickers outliers\n",
    "tickers_outliers = set(df_outliers['ticker_name'])\n",
    "\n",
    "# Criando coluna para marcar se é outlier ou não\n",
    "df_yield_medio['é_outlier'] = df_yield_medio['ticker_name'].isin(tickers_outliers)\n"
   ],
   "id": "709ae3da14bbf058",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_outliers_yield = df_yield_medio[df_yield_medio['é_outlier']]\n",
    "df_nao_outliers_yield = df_yield_medio[~df_yield_medio['é_outlier']]\n"
   ],
   "id": "30c1a8ad6f95db20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_plot = pd.concat([\n",
    "    df_outliers_yield.assign(grupo=\"Outliers\"),\n",
    "    df_nao_outliers_yield.assign(grupo=\"Não Outliers\")\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot individual para cada grupo, com label explícito\n",
    "sns.kdeplot(\n",
    "    data=df_plot[df_plot[\"grupo\"] == \"Outliers\"],\n",
    "    x=\"dividend_yield\",\n",
    "    fill=True,\n",
    "    alpha=0.5,\n",
    "    linewidth=2,\n",
    "    label=\"Outliers\"\n",
    ")\n",
    "\n",
    "sns.kdeplot(\n",
    "    data=df_plot[df_plot[\"grupo\"] == \"Não Outliers\"],\n",
    "    x=\"dividend_yield\",\n",
    "    fill=True,\n",
    "    alpha=0.5,\n",
    "    linewidth=2,\n",
    "    label=\"Não Outliers\"\n",
    ")\n",
    "\n",
    "plt.title(\"Distribuição do Dividend Yield Médio: Outliers vs Não Outliers\", fontsize=14)\n",
    "plt.xlabel(\"Dividend Yield Médio\", fontsize=12)\n",
    "plt.ylabel(\"Densidade\", fontsize=12)\n",
    "plt.legend(title=\"Grupo\", title_fontsize=11, fontsize=10)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "eb8c133048450daa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Hipotese Ruido > Dividendo\n",
    "\n",
    "Potencial"
   ],
   "id": "62915a5022e92383"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "outlier_ticker_teste = df_outliers['ticker_name'][9]",
   "id": "93753588bbfd3b0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "outlier_ticker_teste = \"ABR\"",
   "id": "7bca0d4bbdf2cbf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_cotacoes = \"\"\"with cotacoes AS (\n",
    "    SELECT ticker_name,\n",
    "         Date,\n",
    "         Open,\n",
    "         Close,\n",
    "         Dividends,\n",
    "         LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "    FROM prices\n",
    ")\n",
    "SELECT *, abs(fechamento_ontem - Open) as 'Diferenca Absoluta'\n",
    "FROM cotacoes as c\n",
    "where\n",
    "    fechamento_ontem IS NOT NULL AND\n",
    "    ticker_name = ?;\n",
    "\"\"\"\n",
    "\n",
    "df_cotacoes = pd.read_sql(query_cotacoes, conn, params=(outlier_ticker_teste,))"
   ],
   "id": "a1a91199fffd7841",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_cotacoes.head()",
   "id": "914b88ffe7123622",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dividends_filtrados = df_cotacoes['Dividends'][df_cotacoes['Dividends'] > 0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Densidades\n",
    "sns.kdeplot(df_cotacoes['Diferenca Absoluta'], label='Diferença Absoluta', fill=True, alpha=0.5)\n",
    "sns.kdeplot(dividends_filtrados, label='Dividends', fill=True, alpha=0.5)\n",
    "\n",
    "# Estatísticas\n",
    "media_abs = df_cotacoes['Diferenca Absoluta'].mean()\n",
    "mediana_abs = df_cotacoes['Diferenca Absoluta'].median()\n",
    "std_abs = df_cotacoes['Diferenca Absoluta'].std()\n",
    "\n",
    "media_div = dividends_filtrados.mean()\n",
    "mediana_div = dividends_filtrados.median()\n",
    "std_div = dividends_filtrados.std()\n",
    "\n",
    "# Linhas verticais - Diferença Absoluta\n",
    "plt.axvline(mediana_abs, color='blue', linestyle='--', linewidth=1.2, label='Mediana Diferença')\n",
    "plt.axvline(media_abs, color='blue', linestyle='-', linewidth=1.2, label='Média Diferença')\n",
    "plt.axvline(media_abs + std_abs, color='blue', linestyle=':', linewidth=1.2, label='±1 DP Diferença')\n",
    "plt.axvline(media_abs - std_abs, color='blue', linestyle=':', linewidth=1.2)\n",
    "\n",
    "# Linhas verticais - Dividends\n",
    "plt.axvline(mediana_div, color='orange', linestyle='--', linewidth=1.2, label='Mediana Dividends')\n",
    "plt.axvline(media_div, color='orange', linestyle='-', linewidth=1.2, label='Média Dividends')\n",
    "plt.axvline(media_div + std_div, color='orange', linestyle=':', linewidth=1.2, label='±1 DP Dividends')\n",
    "plt.axvline(media_div - std_div, color='orange', linestyle=':', linewidth=1.2)\n",
    "\n",
    "# Gráfico\n",
    "plt.title('Distribuição: Diferença Absoluta vs. Dividends com Média, Mediana e Desvio Padrão')\n",
    "plt.xlabel('Valor')\n",
    "plt.ylabel('Densidade')\n",
    "plt.legend()\n",
    "plt.xlim(-0.01, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "2c7792f3117aab8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df_outliers\n",
    "df_todos_tickers = pd.read_sql(\"SELECT * FROM tickers_ativos\", conn)\n",
    "df_todos_tickers['e_outlier'] = df_todos_tickers['ticker_name'].isin(df_outliers['ticker_name'])"
   ],
   "id": "dfe34acac1fe93c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def verificar_ruidos_e_dividendos(ticker):\n",
    "    df_cotacoes = pd.read_sql(query_cotacoes, conn, params=(ticker,))\n",
    "\n",
    "    # Converter a coluna Date para datetime\n",
    "    df_cotacoes['Date'] = pd.to_datetime(df_cotacoes['Date'].str.split(' ').str[0])\n",
    "\n",
    "    # Ordenar por data para garantir sequência correta\n",
    "    df_cotacoes.sort_values('Date', inplace=True)\n",
    "\n",
    "    # Descrição geral\n",
    "    descricao_diff = df_cotacoes['Diferenca Absoluta'].describe()\n",
    "    df_filtrada = df_cotacoes[df_cotacoes['Dividends'] > 0]\n",
    "    descricao_div = df_filtrada['Dividends'].describe()\n",
    "\n",
    "    # Lista para armazenar os percentis temporais\n",
    "    percentis_temporais = []\n",
    "\n",
    "    for _, row in df_filtrada.iterrows():\n",
    "        data_dividendo = row['Date']\n",
    "        valor_dividendo = row['Dividends']\n",
    "\n",
    "        # Janela de 30 dias anteriores\n",
    "        janela = df_cotacoes[\n",
    "            (df_cotacoes['Date'] < data_dividendo) &\n",
    "            (df_cotacoes['Date'] >= data_dividendo - pd.Timedelta(days=30)) &\n",
    "            (df_cotacoes['Dividends'] == 0)\n",
    "        ]\n",
    "\n",
    "        # Evita erros em casos com janela vazia\n",
    "        if not janela.empty:\n",
    "            percentil = percentileofscore(janela['Diferenca Absoluta'], valor_dividendo)\n",
    "            percentis_temporais.append(percentil)\n",
    "\n",
    "    # Estatísticas da análise temporal dos dividendos\n",
    "    if percentis_temporais:\n",
    "        media_percentil = sum(percentis_temporais) / len(percentis_temporais)\n",
    "        desvio_percentil = pd.Series(percentis_temporais).std()\n",
    "    else:\n",
    "        media_percentil = None\n",
    "        desvio_percentil = None\n",
    "\n",
    "    estatisticas = {\n",
    "        \"ticker_row\": ticker,\n",
    "        \"Count_Diff\": descricao_diff['count'],\n",
    "        \"Media_Diff\": descricao_diff['mean'],\n",
    "        \"Mediana_Diff\": descricao_diff['50%'],\n",
    "        \"Desvio_Diff\": descricao_diff['std'],\n",
    "        \"1Q_Diff\": descricao_diff['25%'],\n",
    "        \"3Q_Diff\": descricao_diff['75%'],\n",
    "        \"Count_Div\": descricao_div.get('count', 0),\n",
    "        \"Media_Div\": descricao_div.get('mean', 0),\n",
    "        \"Mediana_Div\": descricao_div.get('50%', 0),\n",
    "        \"Desvio_Div\": descricao_div.get('std', 0),\n",
    "        \"1Q_Div\": descricao_div.get('25%', 0),\n",
    "        \"3Q_Div\": descricao_div.get('75%', 0),\n",
    "        \"Media_Percentil_Div_em_Diff30d\": media_percentil,\n",
    "        \"Desvio_Percentil_Div_em_Diff30d\": desvio_percentil\n",
    "    }\n",
    "\n",
    "    return estatisticas\n"
   ],
   "id": "32340d8606085f4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_estatisticas = df_todos_tickers['ticker_name'].apply(verificar_ruidos_e_dividendos).apply(pd.Series)",
   "id": "506cd7aea9a065ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_estatisticas",
   "id": "a3424c0bf2da26dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_todos_tickers = df_todos_tickers.merge(df_estatisticas, left_on='ticker_name', right_on='ticker_row')",
   "id": "89a44f472e01ffd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_todos_tickers.columns",
   "id": "4287dc14b8ec420b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_todos_tickers['diff_medias'] = df_todos_tickers['Media_Diff'] - df_todos_tickers['Media_Div']\n",
    "df_todos_tickers['diff_medianas'] = df_todos_tickers['Mediana_Diff'] - df_todos_tickers['Mediana_Div']\n",
    "df_todos_tickers['razao_medias'] = df_todos_tickers['Media_Diff'] / df_todos_tickers['Media_Div']"
   ],
   "id": "941dd0d29c800ccc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grupo_outlier = df_todos_tickers[df_todos_tickers['e_outlier'] == True]['diff_medias']\n",
    "grupo_normal = df_todos_tickers[df_todos_tickers['e_outlier'] == False]['diff_medias']\n",
    "stat, p = ttest_ind(grupo_outlier, grupo_normal, equal_var=False)\n",
    "print(f'Teste t - Diferença de Médias: stat={stat:.2f}, p-valor={p:.4f}')"
   ],
   "id": "3fc978a13f7be608",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define a variável dependente (y) e independente (X)\n",
    "X = df_todos_tickers[['diff_medias']]\n",
    "X = sm.add_constant(X)  # adiciona o intercepto\n",
    "y = df_todos_tickers['e_outlier'].astype(int)  # transforma True/False em 1/0\n",
    "\n",
    "# Ajusta o modelo logit\n",
    "modelo_logit = sm.Logit(y, X)\n",
    "resultado = modelo_logit.fit()\n",
    "\n",
    "# Exibe o resumo\n",
    "print(resultado.summary())"
   ],
   "id": "556f6cf00be59c80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cria as cores para cada ponto\n",
    "cores = df_todos_tickers['e_outlier'].map({True: 'red', False: 'blue'})\n",
    "\n",
    "# Cria o gráfico de dispersão\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df_todos_tickers['diff_medias'], df_todos_tickers['diff_medianas'], c=cores, alpha=0.7)\n",
    "\n",
    "# Eixos e título\n",
    "plt.xlabel('Diferença da Média de Dividendos para Ruidos')\n",
    "plt.ylabel('Diferença da Mediana de Dividendos para Ruido')\n",
    "plt.title('Dispersão: Diferença Média vs Mediana\\nOutliers em Vermelho')\n",
    "\n",
    "# Grid e layout\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "bae07f19674a4623",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filtra os dados\n",
    "df_outliers = df_todos_tickers[df_todos_tickers['e_outlier'] == True]\n",
    "df_normais = df_todos_tickers[df_todos_tickers['e_outlier'] == False]\n",
    "\n",
    "# Define as cores\n",
    "cores_outliers = df_outliers['e_outlier'].map({True: 'red', False: 'blue'})\n",
    "cores_normais = df_normais['e_outlier'].map({True: 'red', False: 'blue'})\n",
    "\n",
    "# Gráfico 1 - Apenas Outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df_outliers['diff_medias'], df_outliers['diff_medianas'], c=cores_outliers, alpha=0.8)\n",
    "plt.xlabel('Diferença da Média de Dividendos para Ruidos')\n",
    "plt.ylabel('Diferença da Mediana de Dividendos para Ruido')\n",
    "plt.title('Apenas Outliers (em Vermelho)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "fa33dfdb9e27a2e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Gráfico 2 - Apenas Valores Normais\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df_normais['diff_medias'], df_normais['diff_medianas'], c=cores_normais, alpha=0.8)\n",
    "plt.xlabel('Diferença da Média de Dividendos para Ruidos')\n",
    "plt.ylabel('Diferença da Mediana de Dividendos para Ruido')\n",
    "plt.title('Apenas Valores Não-Outliers (Azul)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4036596860aacb08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define o número de intervalos desejados\n",
    "num_bins = 20\n",
    "min_val = df_todos_tickers['diff_medias'].min()\n",
    "max_val = df_todos_tickers['diff_medias'].max()\n",
    "\n",
    "# Cria os intervalos (bins)\n",
    "bins = np.linspace(min_val, max_val, num_bins + 1)\n",
    "\n",
    "# Agrupa os dados em intervalos\n",
    "df_todos_tickers['bin'] = pd.cut(df_todos_tickers['diff_medias'], bins=bins)\n",
    "\n",
    "# Agrupa os dados por intervalo e pelo flag de outlier, contando os registros\n",
    "group_counts = df_todos_tickers.groupby(['bin', 'e_outlier'], observed=True).size().unstack(fill_value=0)\n",
    "\n",
    "# Calcula a coluna Total (soma de outliers e não outliers)\n",
    "group_counts['Total'] = group_counts[False] + group_counts[True]\n",
    "\n",
    "# Reordena as colunas para que Total venha antes de Não Outlier\n",
    "group_counts = group_counts[['Total', False, True]]\n",
    "\n",
    "# Define posições no eixo X para cada intervalo e a largura de cada barra\n",
    "x = np.arange(len(group_counts.index))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plota a barra Total (antes das demais)\n",
    "plt.bar(x - width, group_counts['Total'], width, label='Total', color='gray')\n",
    "# Plota a barra Não Outlier (False)\n",
    "plt.bar(x, group_counts[False], width, label='Não Outlier', color='blue')\n",
    "# Plota a barra Outlier (True)\n",
    "plt.bar(x + width, group_counts[True], width, label='Outlier', color='red')\n",
    "\n",
    "# Formata os labels do eixo X com os intervalos\n",
    "interval_labels = [f'{interval.left:.2f} a {interval.right:.2f}' for interval in group_counts.index]\n",
    "plt.xticks(x, interval_labels, rotation=45)\n",
    "\n",
    "# Eixos e título\n",
    "plt.xlabel('Intervalos da Média de Dividendos')\n",
    "plt.ylabel('Contagem de Valores')\n",
    "plt.title('Contagem por Intervalos da Média de Dividendos\\n(Total, Não Outliers e Outliers)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ae603bda32cafcf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Mapeia cores com base em outliers\n",
    "cores = df_todos_tickers['e_outlier'].map({True: 'red', False: 'blue'})\n",
    "\n",
    "# Cria o gráfico de dispersão\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(\n",
    "    df_todos_tickers['Media_Percentil_Div_em_Diff30d'],\n",
    "    df_todos_tickers['Desvio_Percentil_Div_em_Diff30d'],\n",
    "    c=cores,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Eixos e título\n",
    "plt.xlabel('Média dos Percentis de Dividendos no Ruído (30d)')\n",
    "plt.ylabel('Desvio dos Percentis de Dividendos no Ruído (30d)')\n",
    "plt.title('Dispersão: Média vs Desvio dos Percentis Temporais\\nOutliers em Vermelho')\n",
    "\n",
    "# Grid e layout\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "227a095883a2ae65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define o número de intervalos desejados\n",
    "num_bins = 10\n",
    "min_val = 0\n",
    "max_val = 100\n",
    "\n",
    "# Cria os intervalos (bins)\n",
    "bins = np.linspace(min_val, max_val, num_bins + 1)\n",
    "\n",
    "# Agrupa os dados em intervalos\n",
    "df_todos_tickers['bin'] = pd.cut(df_todos_tickers['Media_Percentil_Div_em_Diff30d'], bins=bins)\n",
    "\n",
    "# Agrupa os dados por intervalo e pelo flag de outlier, contando os registros\n",
    "group_counts = df_todos_tickers.groupby(['bin', 'e_outlier'], observed=True).size().unstack(fill_value=0)\n",
    "\n",
    "# Calcula a coluna Total (soma de outliers e não outliers)\n",
    "group_counts['Total'] = group_counts[False] + group_counts[True]\n",
    "\n",
    "# Reordena as colunas para que Total venha antes de Não Outlier\n",
    "group_counts = group_counts[['Total', False, True]]\n",
    "\n",
    "# Define posições no eixo X para cada intervalo e a largura de cada barra\n",
    "x = np.arange(len(group_counts.index))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plota as barras\n",
    "plt.bar(x - width, group_counts['Total'], width, label='Total', color='gray')\n",
    "plt.bar(x, group_counts[False], width, label='Não Outlier', color='blue')\n",
    "plt.bar(x + width, group_counts[True], width, label='Outlier', color='red')\n",
    "\n",
    "# Formata os labels do eixo X com os intervalos\n",
    "interval_labels = [f'{interval.left:.1f} a {interval.right:.1f}' for interval in group_counts.index]\n",
    "plt.xticks(x, interval_labels, rotation=45)\n",
    "\n",
    "# Eixos e título\n",
    "plt.xlabel('Intervalos da Média dos Percentis dos Dividendos (30d)')\n",
    "plt.ylabel('Contagem de Ativos')\n",
    "plt.title('Contagem por Intervalos da Média dos Percentis\\nTotal, Não Outliers e Outliers')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "999adc171efdeea5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_bins = 10\n",
    "min_val = 0\n",
    "max_val = 100\n",
    "\n",
    "\n",
    "# Cria os intervalos (bins)\n",
    "bins = np.linspace(min_val, max_val, num_bins + 1)\n",
    "df_todos_tickers['bin'] = pd.cut(df_todos_tickers['Media_Percentil_Div_em_Diff30d'], bins=bins)\n",
    "\n",
    "# Agrupa os dados por intervalo e pelo flag de outlier, contando os registros\n",
    "group_counts = df_todos_tickers.groupby(['bin', 'e_outlier'], observed=True).size().unstack(fill_value=0)\n",
    "\n",
    "# Cria coluna Total e calcula os percentuais\n",
    "group_counts['Total'] = group_counts[False] + group_counts[True]\n",
    "group_counts['Não Outlier'] = group_counts[False]\n",
    "group_counts['% Não Outlier'] = round((group_counts[False] / group_counts['Total']) * 100,4)\n",
    "group_counts['Outlier'] = group_counts[True]\n",
    "group_counts['% Outlier'] = round((group_counts[True] / group_counts['Total']) * 100,4)\n",
    "\n",
    "# Reorganiza as colunas\n",
    "df_percentuais = group_counts[['Não Outlier', '% Não Outlier', 'Outlier', '% Outlier', 'Total']].reset_index()\n",
    "df_percentuais.columns.name = None\n",
    "\n",
    "# Mostra o resultado\n",
    "df_percentuais"
   ],
   "id": "5e4bffb090b68f07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_percentuais['bin_str'] = df_percentuais['bin'].astype(str)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df_percentuais['bin_str'], df_percentuais['% Não Outlier'], label='Não Outlier', color='blue')\n",
    "plt.bar(df_percentuais['bin_str'], df_percentuais['% Outlier'], bottom=df_percentuais['% Não Outlier'], label='Outlier', color='red')\n",
    "\n",
    "# Eixos e título\n",
    "plt.xlabel('Faixa da Média dos Percentis de Dividendos (30d)')\n",
    "plt.ylabel('Percentual de Ativos (%)')\n",
    "plt.title('Distribuição Percentual de Outliers vs Não Outliers por Faixa de Média Percentil')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()\n"
   ],
   "id": "ae71f488dc947d7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_todos_tickers.drop(\"ticker_row\",axis=1, inplace=True)\n",
    "df_todos_tickers['bin'] = df_percentuais['bin'].astype(str)\n",
    "df_todos_tickers.to_sql(\"testes_estatisticos_div_diff\",conn)"
   ],
   "id": "c2399cec9f1a36a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Outliers Pontuais Larga Escala",
   "id": "beefb17b4f1b0a6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_cotacoes_por_ativo = \"\"\"\n",
    "with cotacoes AS (\n",
    "    SELECT ticker_name,\n",
    "         Date,\n",
    "         Open,\n",
    "         Close,\n",
    "         Dividends,\n",
    "         LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "    FROM prices\n",
    ")\n",
    "SELECT *\n",
    "FROM cotacoes as c\n",
    "where\n",
    "    fechamento_ontem IS NOT NULL AND\n",
    "    ticker_name == ?;\n",
    "\"\"\""
   ],
   "id": "f493efaf42b277e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_todos_tickers = pd.read_sql(\"SELECT * FROM tickers_ativos\", conn)\n",
    "df_todos_tickers['e_outlier'] = df_todos_tickers['ticker_name'].isin(df_outliers['ticker_name'])"
   ],
   "id": "d9a4326cd8deda6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ticker_row = df_todos_tickers.sample(1)",
   "id": "3635ac38636b70b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ticker_name = ticker_row['ticker_name'].values[0]",
   "id": "48f1d924ee478d69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_sql(query_cotacoes_por_ativo, conn, params=[ticker_name])\n",
    "\n",
    "# Filtra apenas os dias com dividendos\n",
    "df = df[df[\"Dividends\"] != 0]\n",
    "\n",
    "# Criando a variável dependente ajustada\n",
    "y_ajustado = df[\"Open\"] - df[\"fechamento_ontem\"]\n",
    "\n",
    "# Variável independente\n",
    "X = df[[\"Dividends\"]]\n",
    "X = sm.add_constant(X)  # Adiciona intercepto (caso necessário)\n",
    "\n",
    "# Rodando a regressão\n",
    "modelo = sm.OLS(y_ajustado, X).fit()\n",
    "\n",
    "# Teste de cointegração (Engle-Granger) - verificar validade do modelo\n",
    "df[\"residuos\"] = modelo.resid\n",
    "adf_res = adfuller(df[\"residuos\"], autolag=\"AIC\")\n",
    "regressao_valida = adf_res[1] < 0.05  # Se p-valor < 0.05, a regressão é válida"
   ],
   "id": "e040f9d8c1c1d4e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "influence = modelo.get_influence()",
   "id": "add1db9982e58fcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "influence.dfbetas",
   "id": "236c380d008345ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "influence = modelo.get_influence()\n",
    "dfbetas = influence.dfbetas  # shape (n_obs, n_coef)\n",
    "\n",
    "# Coeficiente do dividendo está na coluna 1 (coluna 0 é o intercepto)\n",
    "dfbeta_div = dfbetas[:, 1]\n",
    "\n",
    "# Erro padrão residual\n",
    "s = np.sqrt(modelo.scale)\n",
    "\n",
    "# Matriz (X'X)^-1 → pega a variância do coeficiente dos dividendos\n",
    "C_jj = modelo.normalized_cov_params['Dividends']['Dividends']\n",
    "\n",
    "# Calcula o impacto estimado em unidades reais de beta\n",
    "impacto_estimado = dfbeta_div * s * np.sqrt(C_jj)\n",
    "\n",
    "# Organiza em DataFrame\n",
    "impacto_df = pd.DataFrame({\n",
    "    \"DFBETA_dividendo\": dfbeta_div,\n",
    "    \"Impacto_estimado_no_beta\": impacto_estimado,\n",
    "    \"Indice\": df.index\n",
    "}).set_index(\"Indice\")\n",
    "\n",
    "# Exibe os pontos mais impactantes\n",
    "impacto_df[\"Impacto_abs\"] = impacto_df[\"Impacto_estimado_no_beta\"].abs()\n",
    "impacto_df.sort_values(\"Impacto_abs\", ascending=False, inplace=True)"
   ],
   "id": "706bb40b67595185",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "impacto_df",
   "id": "84cbcafba4d5773f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "modelo.sumary()",
   "id": "c402ca1408514ee3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6dcf7301863753d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Outras analises",
   "id": "bd73634089639f22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Todos os tickers",
   "id": "66b834c22153103c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_sql(\"SELECT * FROM tickers_ativos\", conn)",
   "id": "84aaa6815ecac170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Supondo que seu DataFrame se chama df e tem a coluna 'ticker_name'\n",
    "df_sorted = df.sort_values(by='ticker_name').reset_index(drop=True)\n",
    "\n",
    "# Parâmetros de corte\n",
    "num_columns = 12\n",
    "total_elements = int(np.ceil(len(df_sorted) / num_columns) * num_columns)\n",
    "\n",
    "# Preenchendo com string vazia para completar a matriz\n",
    "padded_values = np.append(df_sorted['ticker_name'].values, [''] * (total_elements - len(df_sorted)))\n",
    "\n",
    "# Convertendo para matriz com 12 colunas, preenchendo por linha (ordem padrão 'C')\n",
    "matrix = padded_values.reshape((-1, num_columns), order='C')\n",
    "\n",
    "# Criando o novo DataFrame\n",
    "df_final = pd.DataFrame(matrix)\n",
    "\n",
    "# Exportando para Excel sem cabeçalho nem índice\n",
    "df_final.to_excel(\"para_tcc/tickers_organizados.xlsx\", index=False, header=False)"
   ],
   "id": "e0e613c97e40f016",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_final",
   "id": "c61a21068f3a359e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Diferença preço ajustado e preço normal",
   "id": "c352d9a1add85d94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM prices\n",
    "WHERE ticker_name = 'INTC'\n",
    "\"\"\", conn)"
   ],
   "id": "a9a9f7e5fdf74095",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.columns",
   "id": "b7a7a366d4c6481c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bd833a5faf84347"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Prepara o DataFrame\n",
    "df['Date'] = pd.to_datetime(df['Date'], utc=True)\n",
    "df = df.sort_values('Date')\n",
    "ticker = df['ticker_name'].iloc[0]\n",
    "\n",
    "fig, (ax_price, ax_gap) = plt.subplots(\n",
    "    2, 1, figsize=(12, 7), sharex=True,\n",
    "    gridspec_kw={'height_ratios': [3, 1]}\n",
    ")\n",
    "\n",
    "# Painel 1 – preços\n",
    "ax_price.plot(df['Date'], df['Close'], label='Fechamento', linewidth=0.9)\n",
    "ax_price.plot(df['Date'], df['Adj Close'], label='Fechamento Ajustado', linewidth=0.9)\n",
    "ax_price.set_ylabel('Preço (USD)')\n",
    "ax_price.legend(loc='upper right')\n",
    "ax_price.grid(True)\n",
    "\n",
    "# Painel 2 – deslocamento\n",
    "gap = df['Adj Close'] - df['Close']\n",
    "ax_gap.fill_between(df['Date'], gap, 0, color='red', alpha=0.4, step='mid')\n",
    "ax_gap.set_ylabel('Deslocamento')\n",
    "ax_gap.set_xlabel('Data')\n",
    "ax_gap.axhline(0, color='black', linewidth=0.8)\n",
    "ax_gap.grid(True)\n",
    "\n",
    "fig.suptitle(f'{ticker} | Fechamento vs Fechamento Ajustado\\nDados coletados em 06/03/2025 \\n Fonte: Yahoo Finance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cda4f8725d74fba1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f7df4ef4de50a64e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Verificando R2 comportamento",
   "id": "a52893dc6e1e14b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "r2s = pd.read_sql(\"SELECT r2 FROM beta_dividendo_bruto\", conn)",
   "id": "dc5094fdef058cb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "r2s.describe()['r2'].apply(lambda x: f'{x:.6f}')",
   "id": "ab6800ce6c7f91c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d11f6eba7851aeec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PDR x Beta",
   "id": "db136831ac89fa34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_pdr = \"\"\"\n",
    "with cotacoes AS (\n",
    "    SELECT\n",
    "        ticker_name,\n",
    "         Date,\n",
    "         Open,\n",
    "         Close,\n",
    "         Dividends,\n",
    "         LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "    FROM prices\n",
    ")\n",
    "SELECT c.ticker_name,\n",
    "       Date,\n",
    "       (fechamento_ontem - Open) / Dividends as PDR\n",
    "FROM cotacoes as c\n",
    "where\n",
    "    fechamento_ontem IS NOT NULL AND\n",
    "    Dividends != 0 AND\n",
    "    ticker_name IN (select ticker_name from tickers_ativos);\n",
    "\"\"\"\n",
    "\n",
    "pdr = pd.read_sql(query_pdr, conn)"
   ],
   "id": "aac863153e124fe1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "estatisticas = pdr.groupby('ticker_name')['PDR'].agg([\n",
    "    'mean',\n",
    "    'std',\n",
    "    'min',\n",
    "    'max',\n",
    "    'median',\n",
    "    lambda x: x.quantile(0.25),\n",
    "    lambda x: x.quantile(0.75),\n",
    "    'count'\n",
    "])\n",
    "\n",
    "estatisticas.columns = [\n",
    "    'pdr_media',\n",
    "    'pdr_desvio_padrao',\n",
    "    'pdr_minimo',\n",
    "    'pdr_maximo',\n",
    "    'pdr_mediana',\n",
    "    'pdr_percentil_25',\n",
    "    'pdr_percentil_75',\n",
    "    'pdr_n'\n",
    "]"
   ],
   "id": "f6b62f2ae3f37358",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pdr segue normal?\n",
    "pdr_global = pdr[\"PDR\"].dropna()\n",
    "stat_global, pval_global = stats.normaltest(pdr_global)\n",
    "\n",
    "print(\"Teste de normalidade global (D’Agostino-Pearson):\")\n",
    "print(f\"Estatística: {stat_global:.4f}, p-valor: {pval_global:.4g}\")\n",
    "print(\"Distribuição NÃO é normal.\" if pval_global < 0.05 else \"Distribuição é aproximadamente normal.\")\n"
   ],
   "id": "dda90bef0eb309dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2. Teste por ativo\n",
    "resultados = []\n",
    "\n",
    "for ticker, grupo in pdr.groupby(\"ticker_name\"):\n",
    "    pdr_vals = grupo[\"PDR\"].dropna()\n",
    "    n = len(pdr_vals)\n",
    "\n",
    "    stat, pval = stats.shapiro(pdr_vals)\n",
    "    metodo = \"Shapiro\"\n",
    "\n",
    "    resultados.append({\n",
    "        \"ticker\": ticker,\n",
    "        \"n_obs\": n,\n",
    "        \"teste\": metodo,\n",
    "        \"p_valor\": pval,\n",
    "        \"eh_normal\": pval >= 0.05\n",
    "    })\n",
    "\n",
    "df_pdr_normalidade = pd.DataFrame(resultados)"
   ],
   "id": "457434ff871ab4fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_pdr_normalidade",
   "id": "b67e7554eda07934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(pdr[\"PDR\"].dropna(), bins=100, edgecolor='black', alpha=0.7)\n",
    "plt.title(\"Distribuição do PDR (geral)\")\n",
    "plt.xlabel(\"PDR\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "ab3a5cf4c85ed143",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dados limpos (sem outliers, se quiser aplicar corte)\n",
    "dados = pdr[\"PDR\"].dropna()\n",
    "dados = dados[(dados >= dados.quantile(0.05)) & (dados <= dados.quantile(0.95))]\n",
    "\n",
    "# Distribuições que vamos testar\n",
    "distribuicoes = [\n",
    "    \"norm\", \"t\", \"lognorm\", \"laplace\", \"expon\", \"gamma\", \"cauchy\", \"beta\"\n",
    "]\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for dist_name in distribuicoes:\n",
    "    dist = getattr(stats, dist_name)\n",
    "\n",
    "    try:\n",
    "        params = dist.fit(dados)\n",
    "        D, p_ks = stats.kstest(dados, dist_name, args=params)\n",
    "        log_likelihood = dist.logpdf(dados, *params).sum()\n",
    "        resultados.append({\n",
    "            \"Distribuição\": dist_name,\n",
    "            \"KS_p\": p_ks,\n",
    "            \"KS_D\": D,\n",
    "            \"Log-Likelihood\": log_likelihood\n",
    "        })\n",
    "    except Exception as e:\n",
    "        resultados.append({\n",
    "            \"Distribuição\": dist_name,\n",
    "            \"Erro\": str(e)\n",
    "        })\n",
    "\n",
    "df_fit = pd.DataFrame(resultados).sort_values(by=\"KS_p\", ascending=False)"
   ],
   "id": "7e061c5d39a8e3db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_fit",
   "id": "e888261f70545424",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remover outliers (percentis 5% a 95%)\n",
    "dados = pdr[\"PDR\"].dropna()\n",
    "dados = dados[(dados >= dados.quantile(0.05)) & (dados <= dados.quantile(0.95))]\n",
    "\n",
    "# Ajustar distribuição t de Student\n",
    "params = stats.t.fit(dados)\n",
    "x = np.linspace(dados.min(), dados.max(), 1000)\n",
    "pdf_fitted = stats.t.pdf(x, *params)\n",
    "\n",
    "# Plotar histograma e curva ajustada\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(dados, bins=100, density=True, alpha=0.6, color='gray', edgecolor='black', label='Histograma do PDR')\n",
    "plt.plot(x, pdf_fitted, 'r-', label='Distribuição t de Student ajustada')\n",
    "plt.title('Ajuste da distribuição t de Student ao PDR')\n",
    "plt.xlabel('PDR')\n",
    "plt.ylabel('Densidade')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "d4be714bb43417be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ajustar distribuição Laplace\n",
    "params = stats.laplace.fit(dados)\n",
    "x = np.linspace(dados.min(), dados.max(), 1000)\n",
    "pdf_fitted = stats.laplace.pdf(x, *params)\n",
    "\n",
    "# Plotar histograma e curva ajustada\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(dados, bins=100, density=True, alpha=0.6, color='gray', edgecolor='black', label='Histograma do PDR')\n",
    "plt.plot(x, pdf_fitted, 'b-', label='Distribuição Laplace ajustada')\n",
    "plt.title('Ajuste da distribuição Laplace ao PDR')\n",
    "plt.xlabel('PDR')\n",
    "plt.ylabel('Densidade')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "d5c989bd67974e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "estatisticas",
   "id": "9b00768a36ca419b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "betas_query = \"\"\"\n",
    "        SELECT\n",
    "            ticker_name,\n",
    "            beta_dividendo,\n",
    "            erro_beta,\n",
    "            significancia_beta,\n",
    "            alfa,\n",
    "            erro_alfa,\n",
    "            significancia_alfa\n",
    "        FROM beta_dividendo_bruto\n",
    "              \"\"\"\n",
    "df_betas = pd.read_sql(betas_query, conn)"
   ],
   "id": "673b5382c7c4cd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_betas",
   "id": "778a8d2e3bb6f95c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dados = df_betas[\"beta_dividendo\"].dropna()\n",
    "dados = dados[(dados >= dados.quantile(0.05)) & (dados <= dados.quantile(0.95))]\n",
    "\n",
    "# Distribuições que vamos testar\n",
    "distribuicoes = [\n",
    "    \"norm\", \"t\", \"lognorm\", \"laplace\", \"expon\", \"gamma\", \"cauchy\", \"beta\"\n",
    "]\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for dist_name in distribuicoes:\n",
    "    dist = getattr(stats, dist_name)\n",
    "\n",
    "    try:\n",
    "        params = dist.fit(dados)\n",
    "        D, p_ks = stats.kstest(dados, dist_name, args=params)\n",
    "        log_likelihood = dist.logpdf(dados, *params).sum()\n",
    "        resultados.append({\n",
    "            \"Distribuição\": dist_name,\n",
    "            \"KS_p\": p_ks,\n",
    "            \"KS_D\": D,\n",
    "            \"Log-Likelihood\": log_likelihood\n",
    "        })\n",
    "    except Exception as e:\n",
    "        resultados.append({\n",
    "            \"Distribuição\": dist_name,\n",
    "            \"Erro\": str(e)\n",
    "        })\n",
    "\n",
    "df_fit = pd.DataFrame(resultados).sort_values(by=\"KS_p\", ascending=False)"
   ],
   "id": "d57fc27cbee69459",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_fit",
   "id": "c219f0cc9f6b3c2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_completo = pd.merge(df_betas, estatisticas, on='ticker_name', how='inner')\n",
    "df_completo"
   ],
   "id": "543545348552b30d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_completo['beta_dividendo'] = -df_completo['beta_dividendo']",
   "id": "40b135dd446ffeba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_completo.columns",
   "id": "618390eb8786cbab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_completo[['beta_dividendo', 'pdr_media']].corr()",
   "id": "68f0bcc50f240ace",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "q05_beta, q95_beta = df_completo[\"beta_dividendo\"].quantile([0.05, 0.95])\n",
    "q05_pdr, q95_pdr = df_completo[\"pdr_media\"].quantile([0.05, 0.95])\n",
    "\n",
    "df_filtered_div = (df_completo[\"beta_dividendo\"] > q05_beta) & (df_completo[\"beta_dividendo\"] < q95_beta)\n",
    "df_filtered = (df_completo[\"pdr_media\"] > q05_pdr) & (df_completo[\"pdr_media\"] < q95_pdr)\n",
    "\n",
    "df_completo = df_completo[df_filtered & df_filtered_div]"
   ],
   "id": "b737853e39d62c27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_completo",
   "id": "6079113ac6b2cc8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular estatísticas\n",
    "media_beta_div = df_completo[\"beta_dividendo\"].mean()\n",
    "media_r = df_completo[\"pdr_media\"].mean()\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.kdeplot(df_completo[\"beta_dividendo\"], fill=True, label=\"$β_{div}$\", bw_adjust=1.0)\n",
    "sns.kdeplot(df_completo[\"pdr_media\"], fill=True, label=\"Média PDR\", bw_adjust=1.0)\n",
    "\n",
    "plt.axvline(media_beta_div, color='r', linestyle='dashed', linewidth=2, label=f'Média $β_{{div}}$: {media_beta_div:.4f}')\n",
    "plt.axvline(media_r, color='b', linestyle='dashed', linewidth=2, label=f'Média PDR: {media_r:.4f}')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Valor\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Comparação da Distribuição de $β_{div}$ e PDR (5%-95%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "45619ba2366c2bb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_completo[\"diferenca\"] = df_completo[\"beta_dividendo\"] - df_completo[\"pdr_media\"]",
   "id": "1b3825dd88e247c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Calcular estatísticas\n",
    "media_diferenca = df_completo[\"diferenca\"].mean()\n",
    "\n",
    "# Criar bins de 0.1\n",
    "min_diff = np.floor(df_completo[\"diferenca\"].min())\n",
    "max_diff = np.ceil(df_completo[\"diferenca\"].max())\n",
    "bins = np.arange(min_diff, max_diff + 0.1, 0.1)\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.hist(df_completo[\"diferenca\"], bins=bins, alpha=0.7, edgecolor='black', label=\"β_div - PDR\")\n",
    "\n",
    "plt.axvline(media_diferenca, color='r', linestyle='dashed', linewidth=2, label=f'Média: {media_diferenca:.4f}')\n",
    "\n",
    "plt.xlabel(\"Diferença ($β_{div}$ - PDR)\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.title(\"Distribuição da Diferença entre $β_{div}$ e PDR (5%-95%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "bf48407afc024755",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bdcba48e50c30caf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def testar_beta_pdr(ticker, alfa, beta, pdr):\n",
    "    query_beta_pdr = f\"\"\"\n",
    "    with cotacao AS (\n",
    "        SELECT\n",
    "            ticker_name,\n",
    "             Date,\n",
    "             Open,\n",
    "             Close,\n",
    "             Dividends,\n",
    "             LAG(Close, 1) OVER (PARTITION BY ticker_name ORDER BY Date) AS fechamento_ontem\n",
    "        FROM prices\n",
    "        WHERE\n",
    "            ticker_name = '{ticker}'\n",
    "    )\n",
    "    SELECT\n",
    "        Open as efetivo,\n",
    "        fechamento_ontem - {beta} * Dividends - {alfa} as previsao_beta,\n",
    "        fechamento_ontem - {pdr} * Dividends as previsao_pdr\n",
    "    FROM\n",
    "        cotacao\n",
    "    WHERE\n",
    "        Dividends > 0\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query_beta_pdr, conn)\n",
    "\n",
    "    if df.empty:\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"n_eventos\": 0,\n",
    "            \"mae_beta\": None,\n",
    "            \"mae_pdr\": None,\n",
    "            \"mse_beta\": None,\n",
    "            \"mse_pdr\": None,\n",
    "            \"rmse_beta\": None,\n",
    "            \"rmse_pdr\": None,\n",
    "            \"melhor_modelo\": None\n",
    "        }\n",
    "\n",
    "    df[\"erro_beta_abs\"] = abs(df[\"efetivo\"] - df[\"previsao_beta\"])\n",
    "    df[\"erro_pdr_abs\"] = abs(df[\"efetivo\"] - df[\"previsao_pdr\"])\n",
    "\n",
    "    df[\"erro_beta_quadrado\"] = (df[\"efetivo\"] - df[\"previsao_beta\"]) ** 2\n",
    "    df[\"erro_pdr_quadrado\"] = (df[\"efetivo\"] - df[\"previsao_pdr\"]) ** 2\n",
    "\n",
    "    mae_beta = df[\"erro_beta_abs\"].mean()\n",
    "    mae_pdr = df[\"erro_pdr_abs\"].mean()\n",
    "    mse_beta = df[\"erro_beta_quadrado\"].mean()\n",
    "    mse_pdr = df[\"erro_pdr_quadrado\"].mean()\n",
    "    rmse_beta = mse_beta ** 0.5\n",
    "    rmse_pdr = mse_pdr ** 0.5\n",
    "\n",
    "    melhor_modelo = \"beta_div\" if rmse_beta < rmse_pdr else \"pdr\"\n",
    "\n",
    "    return {\n",
    "        \"ticker\": ticker,\n",
    "        \"n_eventos\": len(df),\n",
    "        \"mae_beta\": mae_beta,\n",
    "        \"mae_pdr\": mae_pdr,\n",
    "        \"mse_beta\": mse_beta,\n",
    "        \"mse_pdr\": mse_pdr,\n",
    "        \"rmse_beta\": rmse_beta,\n",
    "        \"rmse_pdr\": rmse_pdr,\n",
    "        \"melhor_modelo\": melhor_modelo\n",
    "    }"
   ],
   "id": "4cf2ee0aadfc7cd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_completo[\"alfa\"] = df_completo[\"alfa\"].fillna(0)\n",
    "df_completo['significancia_alfa'] = df_completo['significancia_alfa'].fillna(0)"
   ],
   "id": "25753a946e2d019c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_completo",
   "id": "7c5f77c56e145588",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resultados = df_completo.apply(\n",
    "    lambda row: testar_beta_pdr(\n",
    "        row[\"ticker_name\"],\n",
    "        row['alfa'] if row['significancia_alfa'] < 0.05 else 0,\n",
    "        row[\"beta_dividendo\"],\n",
    "        row[\"pdr_media\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ],
   "id": "4d5772059b969c82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultados = pd.DataFrame(resultados.tolist())",
   "id": "6b8f30215768ad7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultados",
   "id": "739ae6e6cbcfd1b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_completo = pd.merge(df_completo, df_resultados, left_on='ticker_name', right_on='ticker', how='inner')\n",
   "id": "4d21cb8ff667def2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_completo[df_completo['significancia_beta'] < 0.05]",
   "id": "8acd57563e3c09c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Back Teste PDR - β_div",
   "id": "cc0e4bcb6998afb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def testar_ativos():\n",
    "    tickers = pd.read_sql(\"SELECT ticker_name FROM tickers_ativos\", conn)['ticker_name'].tolist()\n",
    "    resultados = []\n",
    "\n",
    "    for ativo in tickers:\n",
    "        query = f\"\"\"\n",
    "        with cotacoes as (\n",
    "            select\n",
    "                ticker_name,\n",
    "                date,\n",
    "                open,\n",
    "                close,\n",
    "                dividends,\n",
    "                lag(close,1) over (partition by ticker_name order by date) as fechamento_ontem\n",
    "            from prices\n",
    "        )\n",
    "        select\n",
    "            ticker_name,\n",
    "            (fechamento_ontem - open)/dividends as pdr,\n",
    "            open,\n",
    "            fechamento_ontem,\n",
    "            dividends\n",
    "        from cotacoes\n",
    "        where fechamento_ontem is not null\n",
    "          and dividends != 0\n",
    "          and ticker_name = '{ativo}'\n",
    "        \"\"\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "        tre, tes = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "        X = sm.add_constant(tre['dividends'], has_constant='add')\n",
    "        y = tre['fechamento_ontem'] - tre['open']\n",
    "        model = sm.OLS(y, X).fit()\n",
    "\n",
    "        params  = model.params\n",
    "        pvals   = model.pvalues\n",
    "        tstats  = model.tvalues\n",
    "\n",
    "        alpha      = float(params.get('const', 0.0))\n",
    "        beta_div   = float(params.get('dividends', np.nan))\n",
    "        pval_beta  = float(pvals.get('dividends', np.nan))\n",
    "        tstat_beta = float(tstats.get('dividends', np.nan))\n",
    "\n",
    "        pdr_mean = tre['pdr'].mean()\n",
    "\n",
    "        delta_beta    = alpha + beta_div  * tes['dividends']\n",
    "        open_beta_pred= tes['fechamento_ontem'] - delta_beta\n",
    "\n",
    "        delta_pdr     = pdr_mean * tes['dividends']\n",
    "        open_pdr_pred = tes['fechamento_ontem'] - delta_pdr\n",
    "\n",
    "        mae_b  = mean_absolute_error(tes['open'], open_beta_pred)\n",
    "        mse_b  = mean_squared_error(tes['open'], open_beta_pred)\n",
    "        rmse_b = np.sqrt(mse_b)\n",
    "\n",
    "        mae_p  = mean_absolute_error(tes['open'], open_pdr_pred)\n",
    "        mse_p  = mean_squared_error(tes['open'], open_pdr_pred)\n",
    "        rmse_p = np.sqrt(mse_p)\n",
    "\n",
    "        melhor = 'beta' if rmse_b < rmse_p else 'pdr'\n",
    "\n",
    "        resultados.append({\n",
    "            'ticker': ativo,\n",
    "            'beta_div': beta_div,\n",
    "            'pval_beta': pval_beta,\n",
    "            'tstat_beta': tstat_beta,\n",
    "            'mae_beta': mae_b,\n",
    "            'mse_beta': mse_b,\n",
    "            'rmse_beta': rmse_b,\n",
    "            'mae_pdr': mae_p,\n",
    "            'mse_pdr': mse_p,\n",
    "            'rmse_pdr': rmse_p,\n",
    "            'melhor_modelo': melhor\n",
    "        })\n",
    "\n",
    "    return resultados"
   ],
   "id": "7e311bfa1759bc1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "back_teste = testar_ativos()",
   "id": "28e4d6edce982603",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_back_teste = pd.DataFrame(back_teste)",
   "id": "1cc7d4fe39d7dfeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_back_teste.describe().T",
   "id": "306c6d1cd01ac62a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_back_teste",
   "id": "c8f7eb4e5c9308f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_back_teste[df_back_teste['pval_beta'] < 0.05]",
   "id": "efc5296c351f40b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = f\"\"\"\n",
    "with cotacoes as (\n",
    "    select\n",
    "        ticker_name,\n",
    "        date,\n",
    "        open,\n",
    "        close,\n",
    "        dividends,\n",
    "        lag(close,1) over (partition by ticker_name order by date) as fechamento_ontem\n",
    "    from prices\n",
    ")\n",
    "select\n",
    "    ticker_name,\n",
    "    (fechamento_ontem - open)/dividends as pdr,\n",
    "    open,\n",
    "    fechamento_ontem,\n",
    "    dividends\n",
    "from cotacoes\n",
    "where fechamento_ontem is not null\n",
    "  and dividends != 0\n",
    "  and ticker_name IN (SELECT ticker_name FROM tickers_ativos)\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "tre, tes = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "X = sm.add_constant(tre['dividends'], has_constant='add')\n",
    "y = tre['fechamento_ontem'] - tre['open']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "params  = model.params\n",
    "pvals   = model.pvalues\n",
    "tstats  = model.tvalues\n",
    "\n",
    "alpha      = float(params.get('const', 0.0))\n",
    "beta_div   = float(params.get('dividends', np.nan))\n",
    "pval_beta  = float(pvals.get('dividends', np.nan))\n",
    "tstat_beta = float(tstats.get('dividends', np.nan))\n",
    "\n",
    "pdr_mean = tre['pdr'].mean()\n",
    "\n",
    "delta_beta    = alpha + beta_div  * tes['dividends']\n",
    "open_beta_pred= tes['fechamento_ontem'] - delta_beta\n",
    "\n",
    "delta_pdr     = pdr_mean * tes['dividends']\n",
    "open_pdr_pred = tes['fechamento_ontem'] - delta_pdr\n",
    "\n",
    "mae_b  = mean_absolute_error(tes['open'], open_beta_pred)\n",
    "mse_b  = mean_squared_error(tes['open'], open_beta_pred)\n",
    "rmse_b = np.sqrt(mse_b)\n",
    "\n",
    "mae_p  = mean_absolute_error(tes['open'], open_pdr_pred)\n",
    "mse_p  = mean_squared_error(tes['open'], open_pdr_pred)\n",
    "rmse_p = np.sqrt(mse_p)\n",
    "\n",
    "melhor = 'beta' if rmse_b < rmse_p else 'pdr'\n",
    "\n",
    "mercado = {\n",
    "    'ticker': \"mercado\",\n",
    "    'beta_div': beta_div,\n",
    "    'pdf': pdr_mean,\n",
    "    'pval_beta': pval_beta,\n",
    "    'tstat_beta': tstat_beta,\n",
    "    'mae_beta': mae_b,\n",
    "    'mse_beta': mse_b,\n",
    "    'rmse_beta': rmse_b,\n",
    "    'mae_pdr': mae_p,\n",
    "    'mse_pdr': mse_p,\n",
    "    'rmse_pdr': rmse_p,\n",
    "    'melhor_modelo': melhor\n",
    "}\n"
   ],
   "id": "142bfe3ef7a14dee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mercado",
   "id": "885e8af342678dba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "X_full = df[['dividends']]\n",
    "y_full = df['fechamento_ontem'] - df['open']\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "lr_beta = LinearRegression().fit(X_full, y_full)\n",
    "scores_beta = -cross_val_score(lr_beta, X_full, y_full,\n",
    "                              scoring='neg_root_mean_squared_error',\n",
    "                              cv=kf)\n",
    "# mesmo para o modelo PDR, substituindo X_full por tes[['dividends']]*pdr_mean\n",
    "print('β_div RMSE:', scores_beta.mean(), '±', scores_beta.std())\n"
   ],
   "id": "1cf5fea87b75e609",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import root_scalar, minimize_scalar\n",
    "\n",
    "# Supondo que 'df' já está carregado no ambiente\n",
    "# X = dividends, Y = fechamento_ontem - open\n",
    "x = df['dividends'].values\n",
    "y = df['fechamento_ontem'].values - df['open'].values\n",
    "\n",
    "# 1. Solução analítica\n",
    "k_star = (x * y).sum() / (x**2).sum()\n",
    "print(f'k* (analítico) = {k_star:.6f}')\n",
    "\n",
    "# 2. Root finding (derivada SSE)\n",
    "def dSSE(k):\n",
    "    return -2 * np.sum(x * (y - k * x))\n",
    "\n",
    "sol = root_scalar(dSSE, bracket=[0, 2])\n",
    "print(f'k* (root finding) = {sol.root:.6f}')\n",
    "\n",
    "# 3. Minimização direta de SSE\n",
    "def SSE(k):\n",
    "    return np.sum((y - k * x)**2)\n",
    "\n",
    "res = minimize_scalar(SSE, bounds=(0, 2), method='bounded')\n",
    "print(f'k* (minimize_scalar) = {res.x:.6f}')\n"
   ],
   "id": "60f18aac37f0f967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8e6d922426b92094",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ultimas Analises",
   "id": "a6eebc2d0c1dd088"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_sql(\"SELECT * FROM beta_dividendo_bruto\", conn)",
   "id": "c5be1892f8086972",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.describe().T",
   "id": "902b0dccd03abff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sum(df['breusch_pagan_pvalue'] >= 0.05)",
   "id": "3543f9726d512e5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sum(df['white_pvalue'] >= 0.05)",
   "id": "58aebabea526055f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
